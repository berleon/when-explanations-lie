{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When Explanations Lie: Why Modified BP Attribution fails\n",
    "\n",
    "This notebook produces the cosine similaries of the relevance vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to install install packages\n",
    "# !pip install tensorflow-gpu==1.13.1\n",
    "# !pip install innvestigate seaborn tqdm deeplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "\n",
    "import innvestigate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import PIL \n",
    "import copy\n",
    "import contextlib\n",
    "\n",
    "import imp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from skimage.measure import compare_ssim \n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from IPython.display import IFrame, display\n",
    "\n",
    "import keras\n",
    "import keras.backend\n",
    "import keras.models\n",
    "\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.applications.imagenet\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "from innvestigate.analyzer.relevance_based.relevance_analyzer import LRP\n",
    "from innvestigate.analyzer.base import AnalyzerNetworkBase, ReverseAnalyzerBase\n",
    "from innvestigate.analyzer.deeptaylor import DeepTaylor\n",
    "from innvestigate.analyzer import DeepLIFTWrapper\n",
    "\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "from when_explanations_lie import *\n",
    "from monkey_patch_lrp_resnet import custom_add_bn_rule\n",
    "import deeplift_resnet  \n",
    "from deeplift_resnet import DeepLiftRelevanceReplacer\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "keras.backend.set_session(sess)\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to imagenet validation\n",
    "imagenet_val_dir = \"/mnt/ssd/data/imagenet/imagenet-raw/validation\"\n",
    "#imagenet_val_dir = \"/home/leonsixt/tmp/imagenet/imagenet-raw/validation/\"\n",
    "# path to examplary image\n",
    "ex_image_path = \"n01534433/ILSVRC2012_val_00015410.JPEG\"\n",
    "# number of images to run the evaluation\n",
    "n_selected_imgs = 200\n",
    "#n_selected_imgs = 10\n",
    "\n",
    "load_weights = True\n",
    "model_names = ['cifar10', 'resnet50', 'vgg16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _, _ = load_model('cifar10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in model.layers:\n",
    "    print(l.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_cifar(n_selected_imgs):\n",
    "    from keras.datasets import cifar10\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    ex_image_idx = 30\n",
    "    np.random.seed(0)\n",
    "    selected_img_idxs = [ex_image_idx] + np.random.choice(\n",
    "        [idx for idx in range(len(x_test)) \n",
    "         if idx != ex_image_idx], \n",
    "        n_selected_imgs - 1).tolist()\n",
    "    \n",
    "\n",
    "    val_images = [(x_test[i][None], y_test[i]) for i in selected_img_idxs]\n",
    "    ex_image, ex_target = val_images[0]\n",
    "    return ex_image, ex_target, ex_image_idx, val_images, selected_img_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class LayerNames:\n",
    "#    def __init__(self, model, model_name):\n",
    "#        if model_name == 'vgg16':\n",
    "#            self._idx2nice = get_vgg16_nice_layer_names()\n",
    "#        elif model_name == 'resnet50':\n",
    "#            self._idx2nice = get_resnet_nice_layer_names(model)\n",
    "#        \n",
    "#        self._nice2idx = OrderedDict([(n, i) for i, n in self._idx2nice.items()])\n",
    "#        \n",
    "#        self._idx2raw = OrderedDict([i, l.name] for i, l in enumerate(model.layers))\n",
    "#        self._raw2idx = OrderedDict([(n, i) for i, n in self._idx2raw.items()])\n",
    "#        \n",
    "#    def to_raw(self, nice_name):\n",
    "#        idx = self.nice_to_idx(nice_name)\n",
    "#        return self.idx_to_raw(idx)\n",
    "#    \n",
    "#    def to_nice(self, raw_name):\n",
    "#        idx = self.raw_to_idx(raw_name)\n",
    "#        return self.idx_to_nice(idx)\n",
    "#    \n",
    "#    def idx_to_nice(self, idx):\n",
    "#        return self._idx2nice[idx]\n",
    "#    \n",
    "#    def idx_to_raw(self, idx):\n",
    "#        return self._idx2raw[idx]\n",
    "#    \n",
    "#    def nice_to_idx(self, nice_name):\n",
    "#        return self._nice2idx[nice_name]\n",
    "#    \n",
    "#    def raw_to_idx(self, raw_name):\n",
    "#        return self._raw2idx[raw_name]\n",
    "#    \n",
    "#    def nice_names(self):\n",
    "#        return list(self._nice2idx.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Meta:\n",
    "    def __init__(self, model, n_selected_images):\n",
    "        (self.ex_image, self.ex_target, self.ex_image_idx, \n",
    "         self.val_images, self.selected_images) = load_images_cifar10(n_selected_images)\n",
    "        self.names = LayerNames(model, 'cifar10')\n",
    "        self.n_layers = len(model.layers)\n",
    "        self.model_name = 'cifar10'\n",
    "        self.output_shapes = get_output_shapes(model)\n",
    "        self.csc_replacement_layers = ['fc6', 'fc5', 'conv4', 'conv3', 'conv2']\n",
    "        self.patterns = None\n",
    "\n",
    "class ImageNetMeta:\n",
    "    def __init__(self, model, model_name, innv_net,  n_val_images):\n",
    "        (self.ex_image, self.ex_target, self.ex_image_idx, \n",
    "         self.val_images, self.selected_images) = load_images_imagenet(\n",
    "            innv_net, imagenet_val_dir, ex_image_path, n_selected_imgs)\n",
    "        self.patterns = innv_net['patterns']\n",
    "        self.names = LayerNames(model, model_name)\n",
    "        self.n_layers = len(model.layers)\n",
    "        self.model_name = 'cifar10'\n",
    "        self.output_shapes = get_output_shapes(model)\n",
    "        self.csc_replacement_layers = ['fc6', 'fc5', 'conv4', 'conv3', 'conv2']\n",
    "        self.n_layers = len(model.layers)\n",
    "    \n",
    "def load_model_and_meta(model_name, load_weights):\n",
    "    if model_name in ['vgg16', 'resnet50']:\n",
    "        model, innv_net, color_conversion = load_model(model_name, load_weights) \n",
    "        meta = ImageNetMeta(model, model_name, innv_net, n_selected_imgs)\n",
    "    elif model_name == 'cifar10':\n",
    "        model, _, _ = load_model('cifar10', load_weights)\n",
    "        meta = CIFAR10Meta(model, n_selected_imgs)\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    return model, meta\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, meta = load_model_and_meta('cifar10', load_weights=True)\n",
    "keras.backend.clear_session()\n",
    "model, meta = load_model_and_meta('vgg16', load_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = OrderedDict()\n",
    "n_layers = OrderedDict()\n",
    "keras.backend.clear_session()\n",
    "model, innv_net, color_conversion = load_model('vgg16', load_weights)\n",
    "(ex_image_vgg, ex_target, ex_image_idx,  \n",
    " val_images, selected_img_idxs) = load_images_imagenet(\n",
    "    innv_net, imagenet_val_dir, ex_image_path, n_selected_imgs)\n",
    "layer_names['vgg16'] = LayerNames(model, 'vgg16')\n",
    "n_layers['vgg16'] = len(model.layers)\n",
    "keras.backend.clear_session()\n",
    "model, innv_net, color_conversion = load_model('resnet50', load_weights)\n",
    "(ex_image, ex_target, ex_image_idx,  \n",
    " val_images, selected_img_idxs) = load_images_imagenet(\n",
    "    innv_net, imagenet_val_dir, ex_image_path, n_selected_imgs)\n",
    "layer_names['resnet50'] = LayerNames(model, 'resnet50')\n",
    "n_layers['resnet50'] = len(model.layers)\n",
    "\n",
    "\n",
    "assert ((ex_image - ex_image_vgg) == 0).all()\n",
    "\n",
    "\n",
    "keras.backend.clear_session()\n",
    "model, _, _ = load_model('cifar10')\n",
    "(ex_image, ex_target, ex_image_idx,  \n",
    " val_images, selected_img_idxs) = load_images_imagenet(\n",
    "    innv_net, imagenet_val_dir, ex_image_path, n_selected_imgs)\n",
    "layer_names['cifar10'] = LayerNames(model, 'cifar10')\n",
    "n_layers['cifar10'] = len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_name = layer_names['resnet50'].idx_to_raw(102)\n",
    "layer_names['resnet50'].to_nice(raw_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names['cifar10'].nice_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "replacement_layers = {\n",
    "    'vgg16':  ['fc3', 'fc1', 'conv4_3', 'conv3_3', 'conv2_2'],\n",
    "    'resnet50': ['dense', 'block5_1', 'block4_2', 'block3_4', 'block3_2', 'block2_2'],\n",
    "    'cifar10': ['fc6', 'fc5', 'conv4', 'conv3', 'conv2'],\n",
    "}\n",
    "\n",
    "output_shapes = get_output_shapes(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmap_postprocess_wrapper(name):\n",
    "    return lambda x: heatmap_postprocess(name, x)\n",
    "\n",
    "input_range = (ex_image.min(), ex_image.max())\n",
    "analysers = get_analyser_params(input_range)\n",
    "\n",
    "attr_names = [n for (n, _, _, _, _) in analysers]\n",
    "    \n",
    "hmap_postprocessing = {\n",
    "    n: hmap_postprocess_wrapper(post_name) for n, _, post_name, _, _ in analysers\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 0.9, 10).tolist() + [0.99, 0.999, 0.9999, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_reversed(hidden):\n",
    "    return [h[1] for h in hidden[1:]]\n",
    "\n",
    "\n",
    "dead_neuron_mask = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    keras.backend.clear_session()\n",
    "    model, innv_net, _ = load_model(model_name, load_weights=True)\n",
    "    analyser = innvestigate.create_analyzer(\n",
    "        \"gradient\", model, reverse_keep_tensors=True)\n",
    "    \n",
    "    analyser.analyze(np.concatenate([img for (img, _) in val_images[:20]], 0))\n",
    "    \n",
    "    grad_hidden = parse_reversed(analyser._reversed_tensors) \n",
    "    dead_neuron_mask[model_name] = [(0 == np.mean(g, 0, keepdims=True)).all(-1, keepdims=True) for g in grad_hidden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    plt.title(model_name + \" - active neurons\")\n",
    "    plt.plot([(m.sum(-1) / m.shape[-1] > 0.999999).mean() for m in dead_neuron_mask[model_name]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_layers = copy.deepcopy(replacement_layers)\n",
    "histogram_layers['vgg16'].extend(['conv1_1', 'input'])\n",
    "histogram_layers['resnet50'].extend(['conv2_1a', 'input'])\n",
    "\n",
    "histogram_layers['vgg16'] = [layer_names['vgg16'].to_raw(l) for l in  histogram_layers['vgg16']]\n",
    "histogram_layers['resnet50'] = [layer_names['resnet50'].to_raw(l) for l in  histogram_layers['resnet50']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dead_neuron_mask['vgg16'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from innvestigate.analyzer import GuidedBackprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "innvestigate.analyzer.analyzers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keras.backend.clear_session()\n",
    "model_name = 'vgg16'\n",
    "model, innv_net, color_conversion = load_model(model_name, load_weights)\n",
    "ex_image, ex_target, val_images, selected_img_idxs = load_val_images(\n",
    "    innv_net, imagenet_val_dir, ex_image_path, n_selected_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_replacement_class(analyser_cls):\n",
    "    assert issubclass(analyser_cls, ReverseAnalyzerBase)\n",
    "    class ReplaceBackward(analyser_cls):\n",
    "        def __init__(self, model, *args, **kwargs):\n",
    "            kwargs['reverse_keep_tensors'] = True\n",
    "            super().__init__(model, *args, **kwargs)\n",
    "        \n",
    "        def _create_analysis(self, *args, **kwargs):\n",
    "            outputs, relevances_per_layer = super()._create_analysis(*args, **kwargs)\n",
    "            self._relevances_per_layer = relevances_per_layer[::-1]\n",
    "            return outputs, relevances_per_layer\n",
    "        \n",
    "        def _get_layer_idx(self, name):\n",
    "            layer = self._model.get_layer(name=name)\n",
    "            return self._model.layers.index(layer)\n",
    "        \n",
    "        def get_relevances(self, input_value, relevance_value,  \n",
    "                           set_layer, selected_layers):\n",
    "            \"\"\"\n",
    "            return relevance values\n",
    "            \"\"\"\n",
    "            sess = keras.backend.get_session()\n",
    "            inp = self._analyzer_model.inputs[0]\n",
    "            set_layer_idx = self._get_layer_idx(set_layer)\n",
    "            \n",
    "            selected_layer_idxs = [\n",
    "                self._get_layer_idx(n) for n in selected_layers]\n",
    "            rel_tensor = self._relevances_per_layer[set_layer_idx-1]\n",
    "            #print(rel_tensor.shape,\n",
    "            #     self._relevances_per_layer[set_layer_idx-1].shape,\n",
    "            #     self._relevances_per_layer[set_layer_idx+1].shape,\n",
    "            #     )\n",
    "            return sess.run(\n",
    "                [self._relevances_per_layer[i] for i in selected_layer_idxs],\n",
    "                feed_dict={ \n",
    "                    inp: input_value,\n",
    "                    rel_tensor: relevance_value\n",
    "           })\n",
    "        \n",
    "    return ReplaceBackward \n",
    "\n",
    "\n",
    "def get_replacement_analyser(model, analyser_cls, **kwargs):\n",
    "    if type(analyser_cls) == str:\n",
    "        analyser_cls = innvestigate.analyzer.analyzers[analyser_cls]\n",
    "    replacement_cls = create_replacement_class(analyser_cls)\n",
    "    \n",
    "    return replacement_cls(model, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    gb_repl = create_replacement_class(GuidedBackprop)(model)\n",
    "    gb_repl.create_analyzer_model()\n",
    "\n",
    "    layer_name = 'activation_43'\n",
    "    layer = gb_repl._model.get_layer(name=layer_name)\n",
    "    print(layer, layer.name) #, layer.weights[0].shape)\n",
    "    \n",
    "    relv_shape = list(layer.output.shape)\n",
    "    print(relv_shape) #, layer.weights[0].shape)\n",
    "    gb_repl._model.layers.index(layer)\n",
    "\n",
    "    n = 2\n",
    "    relvs = gb_repl.get_relevances(\n",
    "        input_value=np.repeat(ex_image, n, axis=0), \n",
    "        relevance_value=np.random.normal(size=[n, ] + relv_shape[1:]),\n",
    "        set_layer=layer_name, \n",
    "        selected_layers=[model.layers[1].name],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(gb_repl._relevances_per_layer), len(model.layers))\n",
    "for idx, (rel, layer) in enumerate(zip(gb_repl._relevances_per_layer, model.layers)):\n",
    "    def get_shape(tensors):\n",
    "        if type(tensors) == list:\n",
    "            return [i.shape for i in tensors]\n",
    "        else:\n",
    "            return tensors.shape\n",
    "    print(idx, layer.name, rel.shape, get_shape(layer.input),  get_shape(layer.output)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class DeepLiftRelevanceReplacer:\n",
    "#    def __init__(self, deeplift_wrapper):\n",
    "#        self.deeplift_wrapper = deeplift_wrapper\n",
    "#        if not hasattr(self.deeplift_wrapper, \"_deep_lift_func\"): \n",
    "#            self.deeplift_wrapper._create_deep_lift_func()    \n",
    "#        self.model = self.deeplift_wrapper._deeplift_model\n",
    "#        self.layers = list(self.model._name_to_layer.values())\n",
    "#        self.layer_names = list(self.model._name_to_layer.keys())\n",
    "#        self.input_layer = self.layers[0]\n",
    "#       \n",
    "#    def _get_layer_idx(self, name):\n",
    "#        deeplift_name = name + '_0'\n",
    "#        layer_names = list(self.model._name_to_layer.keys())\n",
    "#        return layer_names.index(deeplift_name)\n",
    "#    \n",
    "#    def get_relevances(self, input_value,  relevance_value,\n",
    "#                       set_layer, selected_layers, reference=None):\n",
    "#        def run_single(single_image, single_relevance_value, single_reference):\n",
    "#            sess = keras.backend.get_session()\n",
    "#            return sess.run(\n",
    "#                [self.layers[idx]._target_contrib_vars \n",
    "#                 for idx in selected_layer_idxs], \n",
    "#                feed_dict={\n",
    "#                    self.input_layer.get_activation_vars(): single_image,\n",
    "#                    self.input_layer.get_reference_vars(): single_reference,\n",
    "#                    changed_layer._pos_mxts: single_relevance_value,\n",
    "#                    changed_layer._neg_mxts: single_relevance_value, \n",
    "#                })\n",
    "#            \n",
    "#        set_layer_idx = self._get_layer_idx(set_layer)\n",
    "#        changed_layer = self.layers[set_layer_idx]\n",
    "#        selected_layer_idxs = [self._get_layer_idx(name) for name in selected_layers]\n",
    "#        if reference is None:\n",
    "#            reference = np.zeros_like(input_value)\n",
    "#            \n",
    "#        self.layers[-1].set_active()\n",
    "#        \n",
    "#        aggregated_contribs = [[] for _ in selected_layer_idxs]\n",
    "#        for i in range(len(input_value)):\n",
    "#            contribs = run_single(\n",
    "#                input_value[i:i+1],\n",
    "#                relevance_value[i:i+1],\n",
    "#                reference[i:i+1],\n",
    "#            )\n",
    "#            for i, cont in enumerate(contribs):\n",
    "#                aggregated_contribs[i].append(cont)\n",
    "#                \n",
    "#        self.layers[-1].set_inactive()\n",
    "#        \n",
    "#        return [np.concatenate(contrib) for contrib in aggregated_contribs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relvs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    dp_lift = DeepLIFTWrapper(model)\n",
    "    deeplift_csc = DeepLiftRelevanceReplacer(dp_lift)\n",
    "\n",
    "    n = 2\n",
    "    #layer_name = 'activation_43'\n",
    "    layer_name = 'dense_2'\n",
    "    layer = model.get_layer(name=layer_name)\n",
    "    print(layer, layer.name) #, layer.weights[0].shape)\n",
    "    \n",
    "    relv_shape = list(layer.output.shape)\n",
    "    print(relv_shape) #, layer.weights[0].shape)\n",
    "    \n",
    "    relvs = deeplift_csc.get_relevances(\n",
    "        input_value=np.repeat(ex_image, n, axis=0), \n",
    "        set_layer=layer_name, \n",
    "        relevance_value=np.random.normal(size=[n, ] + relv_shape[1:]),\n",
    "        selected_layers=[model.layers[1].name],\n",
    "    )\n",
    "    print(relvs[0].shape, model.layers[1].name, len(relvs))\n",
    "\n",
    "    for i in range(len(relvs[0])):\n",
    "        plt.imshow(relvs[0][i].sum(-1))\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from innvestigate.analyzer.relevance_based.relevance_rule import AlphaBetaRule\n",
    "\n",
    "def alpha_beta_wrapper(alpha, beta):\n",
    "    class AlphaBetaRuleWrapper(AlphaBetaRule):\n",
    "        def __init__(self, layer, state, bias=True, copy_weights=False):\n",
    "            super(AlphaBetaRuleWrapper, self).__init__(layer, state, alpha=alpha, beta=beta, \n",
    "                             bias=bias, copy_weights=copy_weights)\n",
    "            \n",
    "        def __repr__(self):\n",
    "            return \"AlphaBetaRuleWrapper(alpha={}, beta={})\".format(self._alpha, self._beta)\n",
    "        \n",
    "    return AlphaBetaRuleWrapper\n",
    "\n",
    "def get_custom_rule(innv_name, kwargs):\n",
    "    if innv_name == 'lrp.alpha_beta':\n",
    "        return alpha_beta_wrapper(kwargs['alpha'], kwargs['beta'])\n",
    "    elif innv_name == 'lrp.sequential_preset_a':\n",
    "        return alpha_beta_wrapper(1, 0)\n",
    "    elif innv_name == 'lrp.sequential_preset_b':\n",
    "        return alpha_beta_wrapper(2, 1)\n",
    "        \n",
    "for label, innv_name, _, excludes, kwargs in analysers:\n",
    "    print(innv_name, get_custom_rule(innv_name, kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_range = (ex_image.min(), ex_image.max())\n",
    "analysers = get_analyser_params(input_range)\n",
    "\n",
    "attr_names = [n for (n, _, _, _, _) in analysers]\n",
    "print(attr_names)\n",
    "mpl_styles = OrderedDict([\n",
    "    ('GuidedBP',                   {'marker': '$G$', 'color': colors[0]}),\n",
    "    ('Deconv',                     {'marker': '$V$', 'color': colors[1]}),\n",
    "    ('LRP-z',                      {'marker': 'D',   'color': colors[2]}),\n",
    "    ('DTD',                        {'marker': '$T$', 'color': colors[3]}),\n",
    "    ('PatternAttr.',               {'marker': '$P$', 'color': colors[4]}),\n",
    "    ('LRP $\\\\alpha1\\\\beta0$',      {'marker': '<',   'color': colors[0]}),\n",
    "    ('LRP $\\\\alpha2\\\\beta1$',      {'marker': '>',   'color': colors[1]}),\n",
    "    ('LRP $\\\\alpha5\\\\beta4$',      {'marker': '^',   'color': colors[2]}),\n",
    "    ('LRP CMP $\\\\alpha1\\\\beta0$',  {'marker': 's',   'color': colors[3]}),\n",
    "    ('LRP CMP $\\\\alpha2\\\\beta1$',  {'marker': 'P',   'color': colors[4]}),\n",
    "    ('DeepLIFT Rev.C.',            {'marker': '$D$',   'color': colors[0]}),\n",
    "    ('DeepLIFT Resc.',             {'marker': '$D$',   'color': colors[1]}),\n",
    "    ('SmoothGrad',                 {'marker': 'o',   'color': colors[2]}),\n",
    "    ('Gradient',                   {'marker': 'v',   'color': 'black'}),\n",
    "])\n",
    "\n",
    "for i, (name, style) in enumerate(mpl_styles.items()):\n",
    "    assert name in attr_names\n",
    "    plt.plot(np.arange(10), [20-i] * 10, \n",
    "             #markersize=5,\n",
    "             label=name, #+ \" m=\" + style['marker'], \n",
    "             **style)\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacement_layers= {'vgg16': ['fc3'], 'resnet50': ['dense']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(attr_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names, replacement_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[replacement_layer_idx].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb off\n",
    "# replacement_layer_indices = [22]\n",
    "n_sampled_v = 5\n",
    "\n",
    "cos_sim_histograms = OrderedDict()\n",
    "cos_mean = OrderedDict()\n",
    "selected_percentiles = [0, 1, 5, 10, 20, 50, 100]\n",
    "cos_sim_percentiles = OrderedDict()\n",
    "\n",
    "for label, innv_name, _, excludes, kwargs in tqdm.tqdm_notebook(analysers):\n",
    "    if 'exclude_cos_sim' in excludes:\n",
    "        continue\n",
    "    for model_name in model_names[::-1]:\n",
    "        if 'exclude_' + model_name in excludes:\n",
    "            continue\n",
    "        keras.backend.clear_session()\n",
    "        model, innv_net, _ = load_model(model_name, load_weights=load_weights)\n",
    "        model_output_shapes = get_output_shapes(model)\n",
    "        \n",
    "        selected_layers = [layer_names[model_name].to_raw(nice_name) \n",
    "                           for nice_name in layer_names[model_name].nice_names()]\n",
    "        \n",
    "        if innv_name == \"pattern.attribution\":\n",
    "            kwargs['patterns'] = innv_net['patterns']\n",
    "\n",
    "        if innv_name == 'deep_lift.wrapper':\n",
    "            analyser = DeepLIFTWrapper(model, **kwargs)\n",
    "            repl_analyser = DeepLiftRelevanceReplacer(analyser)\n",
    "            del analyser\n",
    "        else:\n",
    "            custom_rule = get_custom_rule(innv_name, kwargs)\n",
    "            with custom_add_bn_rule(custom_rule):\n",
    "                repl_analyser = get_replacement_analyser(\n",
    "                    model, innv_name, **kwargs)\n",
    "                repl_analyser.create_analyzer_model()\n",
    "        for repl_layer_nice in replacement_layers[model_name]:\n",
    "            replacement_layer_idx = layer_names[model_name].nice_to_idx(repl_layer_nice)\n",
    "            repl_shape = model_output_shapes[replacement_layer_idx-1]\n",
    "            repl_layer_raw = model.layers[replacement_layer_idx].name\n",
    "            #print(repl_shape, rep)\n",
    "            cos_per_img = OrderedDict()\n",
    "            \n",
    "            lower_layers = list(itertools.takewhile(lambda n: n != repl_layer_raw, selected_layers))\n",
    "            for img_idx, (img, _) in tqdm.tqdm_notebook(zip(selected_img_idxs, val_images), \n",
    "                desc=\"[{}.{}] {}\".format(model_name, repl_layer_nice, label)):\n",
    "                channels = repl_shape[-1]\n",
    "                if label == \"$\\\\alpha=100, \\\\beta=99$-LRP\":\n",
    "                    # a=100,b=99 sufferes numerical instabilities with std = 1\n",
    "                    std = 1 / np.sqrt(channels)\n",
    "                else:\n",
    "                    std = 1\n",
    "                \n",
    "                img_tiled = np.repeat(img, n_sampled_v, axis=0)\n",
    "                random_relevance = std*np.random.normal(size=(n_sampled_v, ) + repl_shape[1:]) \n",
    "                \n",
    "                relevances = repl_analyser.get_relevances(\n",
    "                    img_tiled, random_relevance, repl_layer_raw, \n",
    "                    lower_layers)\n",
    "                    \n",
    "                cos_sim = cosine_similarities_from_relevances(relevances)\n",
    "                for layer_raw, cs_for_layer in zip(lower_layers, cos_sim):\n",
    "                    # we filter 0 cosine similarites as they only appear practically when the gradients are zero\n",
    "                    cos_per_img[model_name, layer_raw, img_idx] = np.abs(cs_for_layer)\n",
    "\n",
    "            median_for_label = []\n",
    "            percentile_for_label = OrderedDict([(p, []) for p in selected_percentiles])\n",
    "            for layer_raw in lower_layers:\n",
    "                cos_per_layer = np.concatenate([cos_per_img[model_name, layer_raw, img_idx]  \n",
    "                                                for img_idx in selected_img_idxs])\n",
    "                cos_per_layer = cos_per_layer.flatten()\n",
    "\n",
    "                idx = (label, model_name, repl_layer_raw,  layer_raw)\n",
    "                cos_mean[idx] = np.nanmean(cos_per_layer)\n",
    "                \n",
    "                cos_per_layer = cos_per_layer[~np.isnan(cos_per_layer)]\n",
    "                \n",
    "                if len(cos_per_layer) == 0:\n",
    "                    raise ValueError()\n",
    "                    #import pdb\n",
    "                    #pdb.set_trace()\n",
    "                    cos_per_layer = np.array([np.nan])\n",
    "                    \n",
    "                \n",
    "                perc_values = np.percentile(cos_per_layer,  selected_percentiles)\n",
    "                for p, val in zip(selected_percentiles, perc_values):\n",
    "                    percentile_for_label[p].append(val)\n",
    "\n",
    "                if layer_raw in histogram_layers[model_name]:\n",
    "                    if len(cos_per_layer) > 50000:\n",
    "                        ridx = np.random.choice(len(cos_per_layer), 50000, replace=False)\n",
    "                        cos_per_layer_sel = cos_per_layer[ridx]\n",
    "                    else:\n",
    "                        cos_per_layer_sel = cos_per_layer\n",
    "\n",
    "                    cos_sim_histograms[idx] = np.histogram(cos_per_layer_sel, bins)\n",
    "\n",
    "\n",
    "            for p, values in percentile_for_label.items():\n",
    "                cos_sim_percentiles[label, model_name, replacement_layer_idx, p] = np.array(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = False\n",
    "if save_results:\n",
    "    os.makedirs('cache', exist_ok=True)\n",
    "    with open('cache/cos_sim_with_hist_random_weights.pickle', 'wb') as f:\n",
    "        pickle.dump((cos_sim_percentiles, cos_sim_histograms ), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_results = False\n",
    "if load_results:\n",
    "    os.makedirs('cache', exist_ok=True)\n",
    "    with open('cache/cos_sim_with_hist.pickle', 'rb') as f:\n",
    "        cos_sim_percentiles, cos_sim_histograms = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(U, V):\n",
    "    v_norm = V / np.linalg.norm(V, axis=0, keepdims=True)\n",
    "    u_norm = U / np.linalg.norm(U, axis=0, keepdims=True)\n",
    "    return v_norm.T @ u_norm\n",
    "\n",
    "def get_sample_cos_sim_per_layer(output_shapes):\n",
    "    values = []\n",
    "    for layer_idx, shp in output_shapes.items():\n",
    "        ch = shp[-1]\n",
    "        n_samples = 1000\n",
    "        u = np.random.normal(size=(ch, n_samples))\n",
    "        v = np.random.normal(size=(ch, n_samples))\n",
    "        cos = cosine_similarity(v, u)\n",
    "        mask = np.tri(cos.shape[0])\n",
    "        values.append(np.median(np.abs(cos[mask == 1])))\n",
    "    return np.array(values)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_baseline = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    keras.backend.clear_session()\n",
    "    model, _, _ = load_model(model_name)\n",
    "    output_shapes = get_output_shapes(model)\n",
    "    print(len(output_shapes))\n",
    "    cos_sim_baseline[model_name] = get_sample_cos_sim_per_layer(output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_baseline['vgg16'].shape, cos_sim_baseline['resnet50'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = OrderedDict()\n",
    "\n",
    "os.makedirs('figures/cosine_similarity', exist_ok=True)\n",
    "for model_name in model_names[::-1]:\n",
    "    for replacement_layer in replacement_layers[model_name]:\n",
    "        repl_idx = layer_names[model_name].nice_to_idx(replacement_layer)\n",
    "        start_layer = n_layers[model_name] - repl_idx \n",
    "        \n",
    "        \n",
    "        selected_layers = [name for name in layer_names[model_name].nice_names() \n",
    "                           if layer_names[model_name].nice_to_idx(name) <= repl_idx][::-1]\n",
    "        layer_idx = np.array([layer_names[model_name].nice_to_idx(name) \n",
    "                              for name in selected_layers])\n",
    "        \n",
    "        print(layer_idx, repl_idx, start_layer)\n",
    "        #layer_idx = layer_idxs\n",
    "        \n",
    "        plt.figure(figsize=(max(3, len(layer_idx) / 3.8), 3.5)) #3.5))\n",
    "        \n",
    "        \n",
    "        idx = (\"Gradient\", model_name, repl_idx, 50)\n",
    "        if idx not in cos_sim_percentiles:\n",
    "            warnings.warn(\"not found: \" + str(idx))\n",
    "            \n",
    "        style = copy.copy(mpl_styles[\"Gradient\"])\n",
    "        plt.plot(0.5 + np.arange(len(cos_sim_per_label)), 1-cos_sim_per_label, \n",
    "                 label=\"Gradient\", **style)\n",
    "        \n",
    "        for i, (label, _, _, _, _) in enumerate(analysers):\n",
    "            idx = (label, model_name, repl_idx, 50)\n",
    "            if idx not in cos_sim_percentiles:\n",
    "                warnings.warn(\"not found: \" + str(idx))\n",
    "                continue\n",
    "            cos_sim_per_label = cos_sim_percentiles[idx][::-1]\n",
    "            if label == 'Gradient':\n",
    "                continue\n",
    "                style = copy.copy(mpl_styles[label])\n",
    "                style['alpha'] = 0.5\n",
    "            else:\n",
    "                style = copy.copy(mpl_styles[label])\n",
    "            plt.plot(0.5 + np.arange(len(cos_sim_per_label)), 1-cos_sim_per_label, \n",
    "                     label=label, **style)\n",
    "            \n",
    "            if label not in legend:\n",
    "                legend[label] = mpl_styles[label]\n",
    "            \n",
    "        # Random Cos Similarity\n",
    "        # Cos Similarity Base.\n",
    "        #label='Cos Similarity BL'\n",
    "       # style = {'color': (0.25, 0.25, 0.25)}\n",
    "       # plt.plot(0.5 + np.arange(len(layer_idx)-1), 1-cos_sim_baseline[model_name][layer_idx[1:]], \n",
    "       #          # label='Cos. Sim. Baseline', \n",
    "       #          label=label,\n",
    "       #          **style)\n",
    "       # if label not in legend:\n",
    "       #     legend[label] = style\n",
    "        \n",
    "        #plt.legend(bbox_to_anchor=(1, 1))\n",
    "        plt.ylabel('cosine similarity')\n",
    "        plt.xticks(np.arange(len(selected_layers)), selected_layers, rotation=90)\n",
    "        #plt.ylim(-0.05, 1.05)\n",
    "        plt.grid('on', alpha=0.35) #, axis=\"y\")\n",
    "        plt.yscale('log')\n",
    "        plt.ylim(1e-7, 2)\n",
    "        plt.yticks([1, 1e-2, 1e-4, 1e-6, 1e-8], \n",
    "                   labels=[\"0\", \"1-1e-2\", \"1-1e-4\", \"1-1e-6\", \"1-1e-8\"])\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.savefig(\"./figures/cosine_similarity/{}_layer_{}.pdf\".format(model_name, repl_idx),  \n",
    "                    bbox_inches='tight', pad_inches=0)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(cos_mean.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = ! ls figures/cosine_similarity/\n",
    "print(figures)\n",
    "for figure in figures:\n",
    "    display(IFrame(\"figures/cosine_similarity/\" + figure, 800, 600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.5, 3))\n",
    "for label, style in legend.items():\n",
    "    plt.plot([], label=label, alpha=1, **style)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.legend(loc='center')\n",
    "plt.savefig(\"./figures/cos_sim_legend.pdf\",\n",
    "            bbox_inches='tight', pad_inches=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(IFrame(\"./figures/cos_sim_legend.pdf\", 800, 600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr_name, model_name, layer_idx, percentile in cos_sim_percentiles.keys():\n",
    "    if attr_name == 'GuidedBP' and model_name == 'resnet50':\n",
    "        print(attr_name, model_name, layer_idx, percentile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_histograms.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model, innv_net, _ = load_model('resnet50', load_weights=load_weights)\n",
    "model_output_shapes = get_output_shapes(model)\n",
    "\n",
    "selected_layers = [layer_names[model_name].to_raw(nice_name) \n",
    "                   for nice_name in layer_names[model_name].nice_names()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = DeepLIFTWrapper(model, **kwargs)\n",
    "repl_analyser = DeepLiftRelevanceReplacer(analyser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl_analyser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "attr_counts = []\n",
    "labels = []\n",
    "for (attr_name, model_name, repl_layer, layer_idx), (counts, bins) in cos_sim_histograms.items():\n",
    "    if layer_idx != 7:\n",
    "        #print(layer_idx)\n",
    "        continue\n",
    "    lower_09 = counts[bins[:-1] < 0.9].sum()\n",
    "    print(attr_name, counts.sum())\n",
    "    counts_collapsed = np.concatenate([lower_09[None], counts[bins[:-1] >= 0.9]])\n",
    "    bins_int = np.arange(len(counts_collapsed) + 1)\n",
    "    attr_counts.append(counts_collapsed)\n",
    "    labels.append(attr_name)\n",
    "plt.hist([bins_int[:-1]] * len(attr_counts), bins_int, \n",
    "         weights=attr_counts, stacked=True, label=labels)\n",
    "plt.xticks(bins_int, [\"{:.4g}\".format(b) for b in [0] + bins[bins >= 0.9].tolist()], rotation=0)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
