{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When Explanations Lie: Why Modified BP Attribution fails\n",
    "\n",
    "This notebook produces the cosine similaries of the relevance vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to install install packages\n",
    "# !pip install tensorflow-gpu==1.13.1\n",
    "# !pip install innvestigate seaborn tqdm deeplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "\n",
    "import innvestigate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import PIL \n",
    "import copy\n",
    "import contextlib\n",
    "\n",
    "import imp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from skimage.measure import compare_ssim \n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from IPython.display import IFrame, display\n",
    "\n",
    "import keras\n",
    "import keras.backend\n",
    "import keras.models\n",
    "\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.applications.imagenet\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "from innvestigate.analyzer.relevance_based.relevance_analyzer import LRP\n",
    "from innvestigate.analyzer.base import AnalyzerNetworkBase, ReverseAnalyzerBase\n",
    "from innvestigate.analyzer.deeptaylor import DeepTaylor\n",
    "\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "from when_explanations_lie import *\n",
    "from monkey_patch_lrp_resnet import custom_add_bn_rule\n",
    "import deeplift_resnet  \n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to imagenet validation\n",
    "imagenet_val_dir = \"/mnt/ssd/data/imagenet/imagenet-raw/validation\"\n",
    "#imagenet_val_dir = \"/home/leonsixt/tmp/imagenet/imagenet-raw/validation/\"\n",
    "# path to examplary image\n",
    "ex_image_path = \"n01534433/ILSVRC2012_val_00015410.JPEG\"\n",
    "# number of images to run the evaluation\n",
    "#n_selected_imgs = 200\n",
    "n_selected_imgs = 10\n",
    "\n",
    "load_weights = True\n",
    "model_names = ['resnet50', 'vgg16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model, innv_net, color_conversion = load_model('vgg16', load_weights)\n",
    "ex_image_vgg, ex_target, val_images, selected_img_idxs = load_val_images(\n",
    "    innv_net, imagenet_val_dir, ex_image_path, n_selected_imgs)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "model, innv_net, color_conversion = load_model('resnet50', load_weights)\n",
    "ex_image, ex_target, val_images, selected_img_idxs = load_val_images(\n",
    "    innv_net, imagenet_val_dir, ex_image_path, n_selected_imgs)\n",
    "\n",
    "\n",
    "assert ((ex_image - ex_image_vgg) == 0).all()\n",
    "\n",
    "nice_layer_names = get_nice_layer_names(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = {'vgg16': 22, 'resnet50': 177}\n",
    "\n",
    "replacement_layers = {\n",
    "    'vgg16':  ['fc3', 'fc1', 'conv4_3', 'conv3_3', 'conv2_2'],\n",
    "    'resnet50': ['dense', 'block5_1', 'block4_2', 'block3_4', 'block3_2', 'block2_2'],\n",
    "}\n",
    "\n",
    "output_shapes = get_output_shapes(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmap_postprocess_wrapper(name):\n",
    "    return lambda x: heatmap_postprocess(name, x)\n",
    "\n",
    "input_range = (ex_image.min(), ex_image.max())\n",
    "analysers = get_analyser_params(input_range)\n",
    "\n",
    "attr_names = [n for (n, _, _, _, _) in analysers]\n",
    "    \n",
    "hmap_postprocessing = {\n",
    "    n: hmap_postprocess_wrapper(post_name) for n, _, post_name, _, _ in analysers\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 0.9, 10).tolist() + [0.99, 0.999, 0.9999, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_reversed(hidden):\n",
    "    return [h[1] for h in hidden[1:]]\n",
    "\n",
    "\n",
    "dead_neuron_mask = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    keras.backend.clear_session()\n",
    "    model, innv_net, _ = load_model(model_name, load_weights=True)\n",
    "    analyser = innvestigate.create_analyzer(\n",
    "        \"gradient\", model, reverse_keep_tensors=True)\n",
    "    \n",
    "    analyser.analyze(np.concatenate([img for (img, _) in val_images[:20]], 0))\n",
    "    \n",
    "    grad_hidden = parse_reversed(analyser._reversed_tensors) \n",
    "    dead_neuron_mask[model_name] = [(0 == np.mean(g, 0, keepdims=True)).all(-1, keepdims=True) for g in grad_hidden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    plt.title(model_name + \" - active neurons\")\n",
    "    plt.plot([(m.sum(-1) / m.shape[-1] > 0.999999).mean() for m in dead_neuron_mask[model_name]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice_layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_layers = copy.deepcopy(replacement_layers)\n",
    "histogram_layers['vgg16'].extend(['conv1_1', 'input'])\n",
    "histogram_layers['resnet50'].extend(['conv2_1a', 'input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "histogram_layers_idx = OrderedDict()\n",
    "for model_name in model_names:\n",
    "    histogram_layers_idx[model_name] = []\n",
    "    for layer_name in histogram_layers[model_name]:\n",
    "        idx = get_layer_idx_full(model_name, nice_layer_names, layer_name)\n",
    "        histogram_layers_idx[model_name].append(idx) \n",
    "histogram_layers_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dead_neuron_mask['vgg16'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from innvestigate.analyzer import GuidedBackprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keras.backend.clear_session()\n",
    "model_name = 'vgg16'\n",
    "model, innv_net, color_conversion = load_model(model_name, load_weights)\n",
    "ex_image, ex_target, val_images, selected_img_idxs = load_val_images(\n",
    "    innv_net, imagenet_val_dir, ex_image_path, n_selected_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_replacement_class(analyser_cls):\n",
    "    assert issubclass(analyser_cls, ReverseAnalyzerBase)\n",
    "    class ReplaceBackward(analyser_cls):\n",
    "        def __init__(self, model, *args, **kwargs):\n",
    "            kwargs['reverse_keep_tensors'] = True\n",
    "            super().__init__(model, *args, **kwargs)\n",
    "        \n",
    "        def _create_analysis(self, *args, **kwargs):\n",
    "            outputs, relevances_per_layer = super()._create_analysis(*args, **kwargs)\n",
    "            self._relevances_per_layer = relevances_per_layer[::-1]\n",
    "            return outputs, relevances_per_layer\n",
    "        \n",
    "        def _get_layer_idx(self, name):\n",
    "            layer = self._model.get_layer(name='dense_2')\n",
    "            return self._model.layers.index(layer)\n",
    "        \n",
    "        def get_relevances(self, input_value, relevance_value,  \n",
    "                           set_layer, selected_layers):\n",
    "            \"\"\"\n",
    "            return relevance values\n",
    "            \"\"\"\n",
    "            sess = keras.backend.get_session()\n",
    "            inp = self._analyzer_model.inputs[0]\n",
    "            set_layer_idx = self._get_layer_idx(set_layer)\n",
    "            selected_layer_idxs = [\n",
    "                self._get_layer_idx(n) for n in selected_layers]\n",
    "            rel_tensor = self._relevances_per_layer[set_layer_idx]\n",
    "            \n",
    "            return sess.run(\n",
    "                [self._relevances_per_layer[i] for i in selected_layer_idxs],\n",
    "                feed_dict={ \n",
    "                    inp: input_value,\n",
    "                    rel_tensor: relevance_value\n",
    "           })\n",
    "        \n",
    "    return ReplaceBackward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_replacement_analyser(model, analyser_cls, **kwargs):\n",
    "    if type(analyser_cls) == str:\n",
    "        analyser_cls = innvestigate.analyzer.analyzers[analyser_cls]\n",
    "    replacement_cls = create_replacement_class(analyser_cls)\n",
    "    \n",
    "    return replacement_cls(model, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLiftRelevanceReplacer:\n",
    "    def __init__(self, deeplift_wrapper):\n",
    "        self.deeplift_wrapper = deeplift_wrapper\n",
    "        self.model = self.deeplift_wrapper._deeplift_model\n",
    "        self.layers = list(self.model._name_to_layer.values())\n",
    "        self.layer_names = list(self.model._name_to_layer.keys())\n",
    "        self.input_layer = self.layers[0]\n",
    "       \n",
    "    def _get_layer_idx(self, name):\n",
    "        deeplift_name = name + '_0'\n",
    "        layer_names = list(self.model._name_to_layer.keys())\n",
    "        return layer_names.index(deeplift_name)\n",
    "    \n",
    "    def get_relevances(self, input_value,  relevance_value,\n",
    "                       set_layer, selected_layers, reference=None):\n",
    "        def run_single(single_image, single_relevance_value, single_reference):\n",
    "            sess = keras.backend.get_session()\n",
    "            return sess.run(\n",
    "                [self.layers[idx]._target_contrib_vars \n",
    "                 for idx in selected_layer_idxs], \n",
    "                feed_dict={\n",
    "                    self.input_layer.get_activation_vars(): single_image,\n",
    "                    self.input_layer.get_reference_vars(): single_reference,\n",
    "                    changed_layer._pos_mxts: single_relevance_value,\n",
    "                    changed_layer._neg_mxts: single_relevance_value, \n",
    "                })\n",
    "            \n",
    "        set_layer_idx = self._get_layer_idx(set_layer)\n",
    "        changed_layer = self.layers[set_layer_idx]\n",
    "        selected_layer_idxs = [self._get_layer_idx(name) for name in selected_layers]\n",
    "        print(selected_layer_idxs)\n",
    "        if reference is None:\n",
    "            reference = np.zeros_like(input_value)\n",
    "            \n",
    "        self.layers[-1].set_active()\n",
    "        \n",
    "        aggregated_contribs = [[] for _ in selected_layer_idxs]\n",
    "        for i in range(len(input_value)):\n",
    "            contribs = run_single(\n",
    "                input_value[i:i+1],\n",
    "                relevance_value[i:i+1],\n",
    "                reference[i:i+1],\n",
    "            )\n",
    "            for i, cont in enumerate(contribs):\n",
    "                print(cont.shape)\n",
    "                aggregated_contribs[i].append(cont)\n",
    "                \n",
    "        self.layers[-1].set_inactive()\n",
    "        \n",
    "        return [np.concatenate(contrib) for contrib in aggregated_contribs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gb_repl = create_replacement_class(GuidedBackprop)(model)\n",
    "gb_repl.create_analyzer_model()\n",
    "\n",
    "layer = gb_repl._model.get_layer(name='dense_2')\n",
    "print(layer, layer.name, layer.weights[0].shape)\n",
    "gb_repl._model.layers.index(layer)\n",
    "\n",
    "n = 2\n",
    "relvs = gb_repl.get_relevances(\n",
    "    input_value=np.repeat(ex_image, n, axis=0), \n",
    "    relevance_value=np.random.normal(size=(n, 1000)),\n",
    "    set_layer=\"dense_2\", \n",
    "    selected_layers=[model.layers[1].name],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "deeplift_csc = DeepLiftRelevanceReplacer(dp_lift)\n",
    "\n",
    "n = 2\n",
    "relvs = deeplift_csc.get_relevances(\n",
    "    input_value=np.repeat(ex_image, n, axis=0), \n",
    "    set_layer=\"dense_2\", \n",
    "    relevance_value=np.random.normal(size=(n, 1000)),\n",
    "    selected_layers=[model.layers[1].name, model.layers[-3].name],\n",
    ")\n",
    "print(relvs[0].shape, model.layers[1].name, len(relvs))\n",
    "\n",
    "for i in range(len(relvs[0])):\n",
    "    plt.imshow(relvs[0][i].sum(-1))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from innvestigate.analyzer.relevance_based.relevance_rule import AlphaBetaRule\n",
    "\n",
    "def alpha_beta_wrapper(alpha, beta):\n",
    "    class AlphaBetaRuleWrapper(AlphaBetaRule):\n",
    "        def __init__(self, layer, state, bias=True, copy_weights=False):\n",
    "            super(AlphaBetaRuleWrapper, self).__init__(layer, state, alpha=alpha, beta=beta, \n",
    "                             bias=bias, copy_weights=copy_weights)\n",
    "            \n",
    "        def __repr__(self):\n",
    "            return \"AlphaBetaRuleWrapper(alpha={}, beta={})\".format(self._alpha, self._beta)\n",
    "        \n",
    "    return AlphaBetaRuleWrapper\n",
    "\n",
    "def get_custom_rule(innv_name, kwargs):\n",
    "    if innv_name == 'lrp.alpha_beta':\n",
    "        return alpha_beta_wrapper(kwargs['alpha'], kwargs['beta'])\n",
    "    elif innv_name == 'lrp.sequential_preset_a':\n",
    "        return alpha_beta_wrapper(1, 0)\n",
    "    elif innv_name == 'lrp.sequential_preset_b':\n",
    "        return alpha_beta_wrapper(2, 1)\n",
    "        \n",
    "for label, innv_name, _, excludes, kwargs in analysers:\n",
    "    print(innv_name, get_custom_rule(innv_name, kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb off\n",
    "x = np.linspace(0, 2)\n",
    "plt.plot(x, np.sin(x), label=\"LRP ${\\\\alpha1\\\\beta0}$\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_range = (ex_image.min(), ex_image.max())\n",
    "analysers = get_analyser_params(input_range)\n",
    "\n",
    "attr_names = [n for (n, _, _, _, _) in analysers]\n",
    "\n",
    "\n",
    "mpl_styles = OrderedDict([\n",
    "    ('GuidedBP',                   {'marker': '$G$', 'color': colors[0]}),\n",
    "    ('Deconv',                     {'marker': '$V$', 'color': colors[1]}),\n",
    "    ('LRP-z',                      {'marker': 'D',   'color': colors[2]}),\n",
    "    ('DTD',                        {'marker': '$T$', 'color': colors[3]}),\n",
    "    ('PatternAttr.',               {'marker': '$P$', 'color': colors[4]}),\n",
    "    ('LRP $\\\\alpha1\\\\beta0$',      {'marker': '<',   'color': colors[0]}),\n",
    "    ('LRP $\\\\alpha2\\\\beta1$',      {'marker': '>',   'color': colors[1]}),\n",
    "    ('LRP $\\\\alpha5\\\\beta4$',      {'marker': '^',   'color': colors[2]}),\n",
    "    ('LRP CMP $\\\\alpha1\\\\beta0$',  {'marker': 's',   'color': colors[3]}),\n",
    "    ('LRP CMP $\\\\alpha2\\\\beta1$',  {'marker': 'P',   'color': colors[4]}),\n",
    "    ('DeepLift R.Can.',            {'marker': '$D$',   'color': colors[0]}),\n",
    "    ('DeepLift Resc.',             {'marker': '$D$',   'color': colors[1]}),\n",
    "    ('SmoothGrad',                 {'marker': 'o',   'color': colors[2]}),\n",
    "    ('Gradient',                   {'marker': 'v',   'color': 'black'}),\n",
    "])\n",
    "\n",
    "for i, (name, style) in enumerate(mpl_styles.items()):\n",
    "    assert name in attr_names\n",
    "    plt.plot(np.arange(10), [20-i] * 10, \n",
    "             #markersize=5,\n",
    "             label=name, #+ \" m=\" + style['marker'], \n",
    "             **style)\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_layers= {'vgg16': ['fc3'], 'resnet50': ['dense']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names, replacement_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb off\n",
    "# replacement_layer_indices = [22]\n",
    "n_sampled_v = 5\n",
    "\n",
    "cos_sim_histograms = OrderedDict()\n",
    "cos_mean = OrderedDict()\n",
    "selected_percentiles = [0, 1, 5, 10, 20, 50, 100]\n",
    "cos_sim_percentiles = OrderedDict()\n",
    "\n",
    "for label, innv_name, _, excludes, kwargs in tqdm.tqdm_notebook(analysers):\n",
    "    if 'exclude_cos_sim' in excludes:\n",
    "        continue\n",
    "    for model_name in model_names[:1]:\n",
    "        if 'exclude_' + model_name in excludes:\n",
    "            continue\n",
    "        keras.backend.clear_session()\n",
    "        model, innv_net, _ = load_model(model_name, load_weights=load_weights)\n",
    "        model_output_shapes = get_output_shapes(model)\n",
    "            \n",
    "        selected_layers = [model.layers[idx].name \n",
    "                           for idx in nice_layer_names[model_name].keys() ]\n",
    "        if innv_name == \"pattern.attribution\":\n",
    "            kwargs['patterns'] = innv_net['patterns']\n",
    "\n",
    "        if innv_name == 'deeplift.wrapper':\n",
    "            repl_analyser = DeepLiftRelevanceReplacer(analyser)\n",
    "        else:\n",
    "            custom_rule = get_custom_rule(innv_name, kwargs)\n",
    "            with custom_add_bn_rule(custom_rule):\n",
    "                repl_analyser = get_replacement_analyser(\n",
    "                    model, innv_name, **kwargs)\n",
    "                repl_analyser.create_analyzer_model()\n",
    "        for repl_layer_nice in replacement_layers[model_name]:\n",
    "            replacement_layer_idx = get_layer_idx_full(\n",
    "                model_name, nice_layer_names, repl_layer_nice)\n",
    "            repl_shape = model_output_shapes[replacement_layer_idx]\n",
    "            repl_layer_raw = model.layers[replacement_layer_idx].name\n",
    "            cos_per_img = OrderedDict()\n",
    "            print(repl_shape)\n",
    "            print(\"selected\", list(itertools.takewhile(lambda l: l != repl_layer_raw, selected_layers)))\n",
    "            \n",
    "            lower_layers = itertools.takewhile(lambda n: n != repl_layer_raw, selected_layers)\n",
    "            for img_idx, (img, _) in tqdm.tqdm_notebook(zip(selected_img_idxs, val_images), \n",
    "                desc=\"[{}.{}] {}\".format(model_name, repl_layer_nice, label)):\n",
    "                channels = repl_shape[-1]\n",
    "                if label == \"$\\\\alpha=100, \\\\beta=99$-LRP\":\n",
    "                    # a=100,b=99 sufferes numerical instabilities with std = 1\n",
    "                    std = 1 / np.sqrt(channels)\n",
    "                else:\n",
    "                    std = 1\n",
    "                \n",
    "                img_tiled = np.repeat(img, n_sampled_v, axis=0)\n",
    "                random_relevance = std*np.random.normal(size=(n_sampled_v, ) + repl_shape[1:]) \n",
    "                \n",
    "                relevances = repl_analyser.get_relevances(\n",
    "                    img_tiled, random_relevance, repl_layer_raw, \n",
    "                    lower_layers)\n",
    "                    \n",
    "                cos_sim = cosine_similarities_from_relevances(relevances)\n",
    "                \n",
    "                for layer_raw, cs_for_layer in zip(lower_layers, cos_sim):\n",
    "                    # we filter 0 cosine similarites as they only appear practically when the gradients are zero\n",
    "                    cos_per_img[model_name, layer_raw, img_idx] = np.abs(cs_for_layer)\n",
    "\n",
    "            median_for_label = []\n",
    "            percentile_for_label = OrderedDict([(p, []) for p in selected_percentiles])\n",
    "            for layer_raw in lower_layers:\n",
    "                cos_per_layer = np.concatenate([cos_per_img[model_name, layer_raw, img_idx]  for img_idx in selected_img_idxs])\n",
    "                cos_per_layer = cos_per_layer.flatten()\n",
    "\n",
    "                idx = (label, model_name, repl_layer_raw,  layer_idx)\n",
    "                cos_mean[idx] = np.mean(cos_per_layer)\n",
    "\n",
    "                perc_values = np.percentile(cos_per_layer,  selected_percentiles)\n",
    "                for p, val in zip(selected_percentiles, perc_values):\n",
    "                    percentile_for_label[p].append(val)\n",
    "\n",
    "                if layer_idx in histogram_layers_idx[model_name]:\n",
    "\n",
    "                    if len(cos_per_layer) > 50000:\n",
    "                        ridx = np.random.choice(len(cos_per_layer), 50000, replace=False)\n",
    "                        cos_per_layer_sel = cos_per_layer[ridx]\n",
    "                    else:\n",
    "                        cos_per_layer_sel = cos_per_layer\n",
    "\n",
    "                    cos_sim_histograms[idx] = np.histogram(cos_per_layer_sel, bins)\n",
    "\n",
    "\n",
    "            for p, values in percentile_for_label.items():\n",
    "                cos_sim_percentiles[label, model_name, replacement_layer_idx, p] = np.array(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl_analyser.get_relevances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with keras.backend.get_session().as_default():\n",
    "    print(1 - tf.losses.cosine_distance([0, 0], [0, 0], 0).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs[0].shape, outs[-4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = False\n",
    "if save_results:\n",
    "    os.makedirs('cache', exist_ok=True)\n",
    "    with open('cache/cos_sim_with_hist_random_weights.pickle', 'wb') as f:\n",
    "        pickle.dump((cos_sim_percentiles, cos_sim_histograms ), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_results = False\n",
    "if load_results:\n",
    "    os.makedirs('cache', exist_ok=True)\n",
    "    with open('cache/cos_sim_with_hist.pickle', 'rb') as f:\n",
    "        cos_sim_percentiles, cos_sim_histograms = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(U, V):\n",
    "    v_norm = V / np.linalg.norm(V, axis=0, keepdims=True)\n",
    "    u_norm = U / np.linalg.norm(U, axis=0, keepdims=True)\n",
    "    return v_norm.T @ u_norm\n",
    "\n",
    "def get_sample_cos_sim_per_layer(output_shapes):\n",
    "    values = []\n",
    "    for layer_idx, shp in output_shapes.items():\n",
    "        ch = shp[-1]\n",
    "        n_samples = 1000\n",
    "        u = np.random.normal(size=(ch, n_samples))\n",
    "        v = np.random.normal(size=(ch, n_samples))\n",
    "        cos = cosine_similarity(v, u)\n",
    "        mask = np.tri(cos.shape[0])\n",
    "        values.append(np.median(np.abs(cos[mask == 1])))\n",
    "    return np.array(values)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_baseline = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    keras.backend.clear_session()\n",
    "    model, _, _ = load_model(model_name)\n",
    "    output_shapes = get_output_shapes(model)\n",
    "    print(len(output_shapes))\n",
    "    cos_sim_baseline[model_name] = get_sample_cos_sim_per_layer(output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_baseline['vgg16'].shape, cos_sim_baseline['resnet50'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = OrderedDict()\n",
    "\n",
    "os.makedirs('figures/cosine_similarity', exist_ok=True)\n",
    "for model_name in model_names[::-1]:\n",
    "    for replacement_layer in replacement_layers[model_name]:\n",
    "        repl_idx = get_layer_idx_full(model_name, nice_layer_names, replacement_layer)\n",
    "        start_layer = n_layers[model_name] - repl_idx \n",
    "        \n",
    "        layer_names = [name for idx, name in nice_layer_names[model_name].items()\n",
    "                       if idx <= repl_idx][::-1]\n",
    "        layer_idx = np.array([idx for idx, name in nice_layer_names[model_name].items()\n",
    "                       if idx < repl_idx][::-1])\n",
    "        \n",
    "        print(layer_idx, repl_idx, start_layer)\n",
    "        #layer_idx = layer_idxs\n",
    "        \n",
    "        plt.figure(figsize=(max(3, len(layer_idx) / 4), 3.5))\n",
    "        \n",
    "        for i, (label, _, _, _, _) in enumerate(analysers):\n",
    "            idx = (label, model_name, repl_idx, 50)\n",
    "            if idx not in cos_sim_percentiles:\n",
    "                warnings.warn(\"not found: \" + str(idx))\n",
    "                continue\n",
    "            print(len(cos_sim_percentiles[idx]))\n",
    "            cos_sim_per_label = cos_sim_percentiles[idx][layer_idx]\n",
    "            \n",
    "            #cos_sim_per_label = []\n",
    "            #for lidx in layer_idx:\n",
    "            #    cos_sim_per_label.append(cos_mean[label, model_name, repl_idx, lidx])\n",
    "            # try:\n",
    "            #     cos_sim_per_label = cos_sim_percentiles[idx][layer_idx]\n",
    "            # except IndexError:\n",
    "            #     cos_sim_per_label = (cos_sim_baseline[model_name][layer_idx[:1]].tolist() +\n",
    "            #                          cos_sim_percentiles[idx][layer_idx[1:]].tolist())\n",
    "                \n",
    "            plt.plot(0.5 + np.arange(len(cos_sim_per_label)), cos_sim_per_label, label=label, **mpl_styles[label])\n",
    "            \n",
    "            if label not in legend:\n",
    "                legend[label] = mpl_styles[label]\n",
    "            \n",
    "        # Random Cos Similarity\n",
    "        # Cos Similarity Base.\n",
    "        label='Cos Similarity BL'\n",
    "        style = {'color': (0.25, 0.25, 0.25)}\n",
    "        plt.plot(0.5 + np.arange(len(layer_idx)), cos_sim_baseline[model_name][layer_idx], \n",
    "                 # label='Cos. Sim. Baseline', \n",
    "                 label=label,\n",
    "                 **style)\n",
    "        if label not in legend:\n",
    "            legend[label] = style\n",
    "        \n",
    "        #plt.legend(bbox_to_anchor=(1, 1))\n",
    "        plt.ylabel('cosine similarity')\n",
    "        plt.xticks(np.arange(len(layer_names)), layer_names, rotation=90)\n",
    "        plt.ylim(-0.05, 1.05)\n",
    "        plt.grid('on', alpha=0.35) #, axis=\"y\")\n",
    "        plt.savefig(\"./figures/cosine_similarity/{}_layer_{}.pdf\".format(model_name, repl_idx),  \n",
    "                    bbox_inches='tight', pad_inches=0)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(cos_mean.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.5, 3))\n",
    "for label, style in legend.items():\n",
    "    plt.plot([], label=label, alpha=1, **style)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.legend(loc='center')\n",
    "plt.savefig(\"./figures/cos_sim_legend.pdf\",\n",
    "            bbox_inches='tight', pad_inches=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(IFrame(\"./figures/cos_sim_legend.pdf\", 800, 600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr_name, model_name, layer_idx, percentile in cos_sim_percentiles.keys():\n",
    "    if attr_name == 'GuidedBP' and model_name == 'resnet50':\n",
    "        print(attr_name, model_name, layer_idx, percentile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_histograms.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "attr_counts = []\n",
    "labels = []\n",
    "for (attr_name, model_name, repl_layer, layer_idx), (counts, bins) in cos_sim_histograms.items():\n",
    "    if layer_idx != 7:\n",
    "        #print(layer_idx)\n",
    "        continue\n",
    "    lower_09 = counts[bins[:-1] < 0.9].sum()\n",
    "    print(attr_name, counts.sum())\n",
    "    counts_collapsed = np.concatenate([lower_09[None], counts[bins[:-1] >= 0.9]])\n",
    "    bins_int = np.arange(len(counts_collapsed) + 1)\n",
    "    attr_counts.append(counts_collapsed)\n",
    "    labels.append(attr_name)\n",
    "plt.hist([bins_int[:-1]] * len(attr_counts), bins_int, \n",
    "         weights=attr_counts, stacked=True, label=labels)\n",
    "plt.xticks(bins_int, [\"{:.4g}\".format(b) for b in [0] + bins[bins >= 0.9].tolist()], rotation=0)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
