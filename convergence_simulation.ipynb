{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "import tqdm\n",
    "import keras\n",
    "import itertools\n",
    "from IPython.display import display, IFrame\n",
    "from when_explanations_lie import cosine_similarity_dot, load_model\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(U, V):\n",
    "    v_norm =  V / np.linalg.norm(V, axis=0, keepdims=True)\n",
    "    u_norm = U / np.linalg.norm(U, axis=0, keepdims=True)\n",
    "    return (v_norm.T @ u_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_convergence(matrices, metric='std', relu=False, normalize=False):\n",
    "    w_i = np.eye(matrices[0].shape[0])\n",
    "    metrics = []\n",
    "    first = True\n",
    "    for w in matrices:\n",
    "        w_i = w_i @ w\n",
    "        if relu and not first:\n",
    "            w_i = np.clip(w_i, 0, np.inf)\n",
    "        first = False\n",
    "        \n",
    "        if normalize:\n",
    "            w_i = columns_sum_to_one(w_i)\n",
    "        if metric == 'cos_similarity':\n",
    "            scos = cosine_similarity(w_i.T, w_i.T)\n",
    "            tri = np.tri(len(scos))\n",
    "            scos = scos[tri == 1]\n",
    "            scos = scos[~np.isnan(scos)]\n",
    "            metrics.append(np.abs(scos))\n",
    "        else:\n",
    "            metrics.append(metric(w_i))\n",
    "            \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def rows_sum_to_one(w):\n",
    "    return w / w.sum(0, keepdims=True)\n",
    "\n",
    "def columns_sum_to_one(w):\n",
    "    return w / w.sum(1, keepdims=True)\n",
    "\n",
    "def transpose_shapes(shapes):\n",
    "    return [(shp[1], shp[0]) for shp in shapes[::-1]]\n",
    "\n",
    "def conv_to_matrix(kernel):\n",
    "    if len(kernel.shape) == 2:\n",
    "        return kernel\n",
    "    h, w, cin, cout = kernel.shape\n",
    "    return kernel[h//2, w//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, innv_net, _ = load_model('vgg16')\n",
    "\n",
    "vgg_forward_shps = []\n",
    "for layer in model.layers:\n",
    "    try:\n",
    "        w, b = layer.get_weights()\n",
    "        if len(w.shape) == 4:\n",
    "            vgg_forward_shps.append(w[1, 1].shape)\n",
    "        elif w.shape[0] == 25088:\n",
    "            vgg_forward_shps.append(w[:25088 //(7*7), :].shape)\n",
    "        else:\n",
    "            vgg_forward_shps.append(w.shape)\n",
    "            vg\n",
    "        print(vgg_forward_shps[-1])\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "vgg_backward_shps = transpose_shapes(vgg_forward_shps) \n",
    "\n",
    "\n",
    "vgg_parameters = []\n",
    "for layer in model.layers[::-1]:\n",
    "    if isinstance(layer, (keras.layers.Conv2D, keras.layers.Dense)):\n",
    "        w, b = layer.get_weights()\n",
    "        if len(w.shape) == 4:\n",
    "            w = conv_to_matrix(w)\n",
    "            \n",
    "        print(w.shape) \n",
    "        if len(w) == 25088:\n",
    "            cin, cout = w.shape\n",
    "            w = w.reshape((7, 7, cin // (7*7), cout))\n",
    "            w = w[3, 3]\n",
    "        vgg_parameters.append((w, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_weights = []\n",
    "for parameters, pattern in zip(vgg_parameters, innv_net['patterns'][::-1]):\n",
    "    w, b = parameters\n",
    "    pattern_mat = conv_to_matrix(pattern)\n",
    "    if pattern_mat.shape[0] == 25088:\n",
    "        cin, cout = pattern_mat.shape\n",
    "        pattern_mat = pattern_mat.reshape((7, 7, cin // (7*7), cout))\n",
    "        pattern_mat = pattern_mat[3, 3]\n",
    "    pattern_weights.append([w * pattern_mat, np.zeros_like(b)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.random.normal(size=(64, 64))\n",
    "cos_sim = cosine_similarity_dot(w, np.ones_like(w))\n",
    "print(cos_sim.shape,(cos_sim < 0)[None].shape)\n",
    "mask = np.repeat((cos_sim < 0)[None], 64, axis=0).T\n",
    "w[mask] = -w[mask]  \n",
    "\n",
    "cosine_similarity_dot(w, np.ones_like(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim_great_zero(w, reference=None):\n",
    "    if reference is None:\n",
    "        reference = np.ones_like(w)\n",
    "    cos_sim = cosine_similarity_dot(w, reference)\n",
    "    mask = np.repeat((cos_sim < 0)[None], len(w[0]), axis=0).T\n",
    "    w[mask] = -w[mask]  \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((w.T @ w.T).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_size = 128\n",
    "square_shapes = [(square_size, square_size) for _ in range(len(vgg_backward_shps))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 20\n",
    "input_size = 32\n",
    "\n",
    "with_relu = True\n",
    "no_relu = False\n",
    "use_nn = True\n",
    "use_sq = False\n",
    "\n",
    "square_size = 128\n",
    "square_shapes = [(square_size, square_size) for _ in range(len(vgg_forward_shps))]\n",
    "\n",
    "\n",
    "sq_nn_convergences = []\n",
    "if use_sq:\n",
    "    sq_nn_convergences.extend([\n",
    "        # label, shapes, relu, matrix, metric\n",
    "        ('sq vanilla', square_shapes, no_relu, lambda s: np.random.normal(size=s)), \n",
    "        ('sq ReLU', square_shapes, with_relu, lambda s: np.random.normal(size=s)), \n",
    "        ('sq stocastic', square_shapes, no_relu, lambda s: rows_sum_to_one(np.abs(np.random.normal(size=s)))), \n",
    "        ('sq positive', square_shapes, no_relu, lambda s: np.abs(np.random.normal(size=s))), \n",
    "        ('sq non-neg.',   square_shapes, no_relu, lambda s: np.maximum(0, np.random.normal(size=s))), \n",
    "        \n",
    "        \n",
    "    ])\n",
    "\n",
    "if use_nn:\n",
    "    sq_nn_convergences.extend([\n",
    "        ('vanilla',       vgg_backward_shps, no_relu, lambda s: np.random.normal(size=s)), \n",
    "        ('ReLU',  vgg_backward_shps, with_relu, lambda s: np.random.normal(size=s)), \n",
    "        ('ReLU learned',   vgg_backward_shps, with_relu, vgg_parameters), \n",
    "        ('pattern $A \\\\odot W$', vgg_backward_shps, no_relu,\n",
    "             pattern_weights),\n",
    "        ('stocastic', vgg_backward_shps, no_relu, lambda s: rows_sum_to_one(np.abs(np.random.normal(size=s)))), \n",
    "        ('postive',   vgg_backward_shps, no_relu, lambda s: np.abs(np.random.normal(size=s))), \n",
    "        ('non-neg.',   vgg_backward_shps, no_relu, lambda s: np.maximum(0, np.random.normal(size=s))), \n",
    "        #('NN ReLU Forw.', vgg_forward_shps, with_relu, lambda s: np.random.normal(size=s)), \n",
    "    ])\n",
    "\n",
    "\n",
    "def get_alpha_beta_matrix(a, b):\n",
    "    def wrapper(shape):\n",
    "        w = np.random.normal(size=shape)\n",
    "        w_plus = w * (w >= 0)\n",
    "        w_neg = w * (w < 0)      \n",
    "        return a * w_plus + b * w_neg\n",
    "    return wrapper\n",
    "\n",
    "def neg_idx_matrix(lam):\n",
    "    def wrapper(shape):\n",
    "        w = np.abs(np.random.normal(size=shape))\n",
    "        m = (np.random.uniform(size=shape) > lam)\n",
    "        return w * m - (1-m) * w\n",
    "    return wrapper\n",
    "\n",
    "def sq_alpha_beta(alpha):\n",
    "    beta = alpha - 1\n",
    "    return ('sq $\\\\alpha={},\\\\beta={}$'.format(alpha, beta), \n",
    "            square_shapes, no_relu, get_alpha_beta_matrix(alpha, beta))\n",
    "\n",
    "def nn_alpha_beta(alpha):\n",
    "    beta = alpha - 1\n",
    "    return ('$\\\\alpha={},\\\\beta={}$'.format(alpha, beta), \n",
    "            vgg_backward_shps, no_relu, get_alpha_beta_matrix(alpha, beta))\n",
    "\n",
    "alpha_beta_conv = [\n",
    "#    sq_alpha_beta(1),\n",
    "#    sq_alpha_beta(2),\n",
    "#    sq_alpha_beta(3),\n",
    "#    sq_alpha_beta(4),\n",
    "#    sq_alpha_beta(5),\n",
    "#    sq_alpha_beta(10),\n",
    "    \n",
    "    nn_alpha_beta(10),\n",
    "    nn_alpha_beta(5),\n",
    "    nn_alpha_beta(4),\n",
    "    nn_alpha_beta(3),\n",
    "    nn_alpha_beta(2),\n",
    "    nn_alpha_beta(1),\n",
    "]\n",
    "\n",
    "#neg_idx_convergences = []\n",
    "#\n",
    "#for lam in [0, 0.4, 0.45, 0.5, .65, 0.8, 1]:\n",
    "#    #f use_nn:\n",
    "#    #   lambda_convergences.append(\n",
    "#    #       ('NN $\\\\lambda={}$'.format(lam), vgg_backward_shps, no_relu, get_alpha_beta_matrix(lam))) \n",
    "#        \n",
    "#    neg_idx_convergences.append(\n",
    "#        ('SQ IDX $\\\\lambda={}$'.format(lam), square_shapes, no_relu, neg_idx_matrix(lam))\n",
    "#    )\n",
    "    \n",
    "convergences = alpha_beta_conv + sq_nn_convergences\n",
    "#convergences = sq_nn_convergences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(convergences):\n",
    "    return [l for l, _, _, _ in convergences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = OrderedDict()\n",
    "\n",
    "for label, shapes, with_relu, get_matrix in tqdm.tqdm_notebook(convergences):\n",
    "        \n",
    "    for i in tqdm.tqdm_notebook(range(n_samples), desc=label):\n",
    "        input = np.random.normal(size=(input_size, shapes[0][0]))\n",
    "        #print(input.shape)\n",
    "        if type(get_matrix) == list:\n",
    "            matrices = [w.T for w, b in get_matrix]\n",
    "        else:\n",
    "            matrices = [get_matrix(shp) for shp in shapes]\n",
    "        vals = measure_convergence([input] + matrices, metric='cos_similarity', relu=with_relu)\n",
    "        for itr, v in enumerate(vals):\n",
    "            corrs[label, i, itr] = np.nanmean(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = [\n",
    "    \"o\", #circle\n",
    "    \"v\", #triangle_down\n",
    "    \"^\", #triangle_up\n",
    "    \"X\", #star\n",
    "    \"s\", #square\n",
    "    \"D\", #diamond\n",
    "    \"<\", #triangle_left\n",
    "    \"P\", #plus (filled)\n",
    "    \"$O$\", \n",
    "    \">\",\n",
    "    \"$V$\", #hexagon2\n",
    "    \"$P$\", \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p figures/convergence_simulation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_convergence(values, labels, linestyles, conf_intervals=None, title=None, save_path=None, ylogscale=False, clip_eps=1e-15,\n",
    "                     legend='right'):\n",
    "    def handle_log(x):\n",
    "        return 1 - x\n",
    "    \n",
    "    if conf_intervals is None:\n",
    "        conf_intervals = itertools.repeat((None, None))\n",
    "    with sns.axes_style('ticks', {'font.family': 'serif'}):\n",
    "        plt.figure(figsize=(3.9, 2.2))\n",
    "        for value, (conf_lower, conf_upper), label, linestyle in zip(\n",
    "            values, conf_intervals, labels, linestyles):\n",
    "            \n",
    "            xs = np.arange(len(value))\n",
    "            if ylogscale:\n",
    "                inv_value = 1 - value\n",
    "                _ = plt.semilogy(xs, inv_value, label=label, **linestyle)\n",
    "                #plt.ylim(1, 1e-10)\n",
    "                if conf_upper is not None:\n",
    "                    conf_upper = 1 - conf_upper\n",
    "                    conf_lower = 1 - conf_lower\n",
    "                    conf_upper[inv_value < clip_eps] = np.nan\n",
    "                    conf_lower[inv_value < clip_eps] = np.nan\n",
    "                    \n",
    "            else:\n",
    "                _ = plt.plot(xs, value, label=label, **linestyle)\n",
    "            if conf_upper is not None:\n",
    "                _ = plt.fill_between(xs, conf_upper, conf_lower, alpha=0.25, color=linestyle['color'])\n",
    "        plt.title(title)\n",
    "        if legend == 'left':\n",
    "            plt.legend(bbox_to_anchor=(-.3, 1) )\n",
    "        else:\n",
    "            plt.legend(bbox_to_anchor=(1, 1) )\n",
    "        plt.grid(True)\n",
    "        ymin = 1e-12\n",
    "        _, ymax = plt.ylim()\n",
    "        plt.ylim(ymax, ymin)\n",
    "        \n",
    "        locs, labels = plt.yticks()\n",
    "        locs = [l for l in locs if ymin < l < 1]\n",
    "        plt.yticks(locs, labels=[\"1 - {:.0e}\".format(l).replace(\"-0\", \"-\") for l in locs])\n",
    "        \n",
    "        #plt.yticks(1 - np.array([10**(-i) for i in range(10)]))\n",
    "        plt.xlabel('multiplications')\n",
    "        if ylogscale:\n",
    "            plt.ylabel('cosine similarity')\n",
    "        else:\n",
    "            plt.ylabel('abs. cosine similarity')\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, bbox_inches='tight', pad_inches=0.03)\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "def collect_corr(corrs, selected_conv, percentile=99):\n",
    "    values = []\n",
    "    conf_int = []\n",
    "    for label, shapes, _, _ in selected_conv:\n",
    "        corr_per_label = np.array([\n",
    "            [corrs[label, i, itr] for itr in range(1+len(shapes))]\n",
    "            for i in range(n_samples)\n",
    "        ])\n",
    "        median = np.median(corr_per_label, 0)\n",
    "        p = (100 - percentile) / 2\n",
    "        lower = np.percentile(corr_per_label, p, axis=0)\n",
    "        upper = np.percentile(corr_per_label, 100 - p, axis=0)\n",
    "        values.append(median)\n",
    "        conf_int.append((lower, upper))\n",
    "    return values, conf_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, conf_int = collect_corr(corrs, sq_nn_convergences, percentile=99)\n",
    "\n",
    "\n",
    "k = 6\n",
    "color_palette = sns.color_palette('colorblind', k)\n",
    "linestyles = [{'linestyle': l, 'color': c, 'marker': m} for l, c, m in zip(\n",
    "    [\"-\"] * k + [\"--\"] *k , \n",
    "    itertools.cycle(iter(color_palette)),\n",
    "    markers\n",
    ")]\n",
    "\n",
    "labels = get_labels(sq_nn_convergences)\n",
    "#labels[0] = \"$s_\\\\cos(W, \\\\vec{1}) > 0$\"\n",
    "#labels[1] = \"pattern $A \\\\odot W$\"\n",
    "plot_convergence(values, labels, linestyles[:len(values)], \n",
    "                 save_path=\"figures/convergence_simulation/convergence_nn_sq.pdf\",\n",
    "                 ylogscale=True, legend='right'\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(IFrame(\"figures/convergence_simulation/convergence_nn_sq.pdf\", 800, 600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, conf_int = collect_corr(corrs, alpha_beta_conv, percentile=95)\n",
    "\n",
    "\n",
    "nc = 6\n",
    "color_palette = sns.color_palette('colorblind', nc)\n",
    "linestyles = [{'linestyle': l, 'color': c, 'marker': m} for l, c, m in zip(\n",
    "    [\"-\"] * nc + [\"--\"] *nc , itertools.cycle(iter(color_palette)), markers)]\n",
    "\n",
    "plot_convergence(values, get_labels(alpha_beta_conv), linestyles[:len(values)], \n",
    "                 #conf_int, \n",
    "                 #title=\"$\\\\lambda W^+ + (1 - \\\\lambda) W^-$\", \n",
    "                 save_path=\"figures/convergence_simulation/convergence_ab.pdf\",\n",
    "                 ylogscale=True, \n",
    "                 clip_eps=1e-20\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(IFrame(\"figures/convergence_simulation/convergence_ab.pdf\", 800, 600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
