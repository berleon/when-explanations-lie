{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When Explanations Lie: Why Modified BP Attribution fails\n",
    "\n",
    "This notebook produces the cosine similaries of the relevance vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to install install packages\n",
    "# !pip install tensorflow-gpu==1.13.1\n",
    "# !pip install innvestigate seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "\n",
    "import innvestigate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import PIL \n",
    "import copy\n",
    "import contextlib\n",
    "\n",
    "import imp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from skimage.measure import compare_ssim \n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from IPython.display import IFrame, display\n",
    "\n",
    "import keras\n",
    "import keras.backend\n",
    "import keras.models\n",
    "\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.applications.imagenet\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "from innvestigate.analyzer.relevance_based.relevance_analyzer import LRP\n",
    "from innvestigate.analyzer.base import AnalyzerNetworkBase, ReverseAnalyzerBase\n",
    "from innvestigate.analyzer.deeptaylor import DeepTaylor\n",
    "\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "from when_explanations_lie import *\n",
    "from monkey_patch import custom_add_bn_rule\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import deeplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to imagenet validation\n",
    "imagenet_val_dir = \"/mnt/ssd/data/imagenet/imagenet-raw/validation\"\n",
    "#imagenet_val_dir = \"/home/leonsixt/tmp/imagenet/imagenet-raw/validation/\"\n",
    "# path to examplary image\n",
    "ex_image_path = \"n01534433/ILSVRC2012_val_00015410.JPEG\"\n",
    "# number of images to run the evaluation\n",
    "#n_selected_imgs = 200\n",
    "n_selected_imgs = 10\n",
    "\n",
    "load_weights = True\n",
    "model_names = ['resnet50', 'vgg16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.backend.clear_session()\n",
    "#model, innv_net, color_conversion = load_model('vgg16', load_weights)\n",
    "#ex_image_vgg, ex_target, val_images, selected_img_idxs = load_val_images(\n",
    "#    innv_net, imagenet_val_dir, ex_image_path, n_selected_imgs)\n",
    "#\n",
    "#keras.backend.clear_session()\n",
    "#model, innv_net, color_conversion = load_model('resnet50', load_weights)\n",
    "#ex_image, ex_target, val_images, selected_img_idxs = load_val_images(\n",
    "#    innv_net, imagenet_val_dir, ex_image_path, n_selected_imgs)\n",
    "#\n",
    "#\n",
    "#assert ((ex_image - ex_image_vgg) == 0).all()\n",
    "#\n",
    "#nice_layer_names = get_nice_layer_names(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "#model, innv_net, color_conversion = load_model('vgg16', load_weights=True)\n",
    "#ex_image_vgg, ex_target, val_images, selected_img_idxs = load_val_images(\n",
    "#    innv_net, imagenet_val_dir, ex_image_path, n_selected_imgs)\n",
    "#\n",
    "#\n",
    "#model_random, innv_net, color_conversion = load_model('vgg16', load_weights=False)\n",
    "#ex_image_vgg, ex_target, val_images, selected_img_idxs = load_val_images(\n",
    "#    innv_net, imagenet_val_dir, ex_image_path, n_selected_imgs)\n",
    "\n",
    "model_cascading, innv_net, color_conversion = load_model('resnet50', load_weights=True)\n",
    "ex_image, ex_target, val_images, selected_img_idxs = load_val_images(\n",
    "    innv_net, imagenet_val_dir, ex_image_path, n_selected_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplift.layers import Dense, Concat, Merge\n",
    "from deeplift.layers.core import DenseMxtsMode, SingleInputMixin, Node, NoOp\n",
    "from deeplift.conversion.kerasapi_conversion import KerasKeys\n",
    "import keras.backend as K\n",
    "from keras.utils.generic_utils import transpose_shape\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monkey_patch_Merge_compute_shape(self, input_shapes):                       \n",
    "    shape = []                                                                  \n",
    "    # don't recompute input shapes\n",
    "    # input_shapes = [an_input.get_shape() for an_input in self.inputs]         \n",
    "    assert len(set(len(x) for x in input_shapes)) == 1, (\n",
    "      \"all inputs should have the same num\"+                                    \n",
    "      \" of dims - got: \"+str(input_shapes))          \n",
    "    for dim_idx in range(len(input_shapes[0])):    \n",
    "        lengths_for_that_dim = [input_shape[dim_idx]\n",
    "                                for input_shape in input_shapes]\n",
    "        if (dim_idx != self.axis):\n",
    "            assert len(set(lengths_for_that_dim))==1, (\n",
    "                   \"lengths for dim \"+str(dim_idx)  \n",
    "                   +\" should be the same, got: \"+str(lengths_for_that_dim))\n",
    "            shape.append(lengths_for_that_dim[0])\n",
    "        else:\n",
    "            shape.append(self.compute_shape_for_merge_axis(                     \n",
    "                               lengths_for_that_dim))                           \n",
    "    return shape     \n",
    "Merge._compute_shape = monkey_patch_Merge_compute_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from: https://github.com/kundajelab/deeplift/pull/76/files\n",
    "\n",
    "class GlobalAvgPool2D(SingleInputMixin, Node):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(GlobalAvgPool2D, self).__init__(**kwargs)\n",
    "\n",
    "    def _compute_shape(self, input_shape):\n",
    "        assert len(input_shape)==4\n",
    "        shape_to_return = [None, input_shape[-1]]\n",
    "        return shape_to_return\n",
    "\n",
    "    def _build_activation_vars(self, input_act_vars):\n",
    "        return tf.reduce_mean(input_act_vars, axis=(1,2))\n",
    "\n",
    "    def _build_pos_and_neg_contribs(self):\n",
    "        inp_pos_contribs, inp_neg_contribs =\\\n",
    "            self._get_input_pos_and_neg_contribs()\n",
    "        pos_contribs = self._build_activation_vars(inp_pos_contribs)\n",
    "        neg_contribs = self._build_activation_vars(inp_neg_contribs)\n",
    "        return pos_contribs, neg_contribs\n",
    "\n",
    "    def _grad_op(self, out_grad):\n",
    "        height = self._get_input_activation_vars().get_shape().as_list()[1]\n",
    "        width = self._get_input_activation_vars().get_shape().as_list()[2]\n",
    "        mask = (tf.ones_like(self._get_input_activation_vars())/\n",
    "                float(width*height))\n",
    "        return tf.multiply(out_grad[:, None, None, :], mask)\n",
    "\n",
    "    def _get_mxts_increments_for_inputs(self):\n",
    "        pos_mxts_increments = self._grad_op(self.get_pos_mxts())\n",
    "        neg_mxts_increments = self._grad_op(self.get_neg_mxts())\n",
    "        return pos_mxts_increments, neg_mxts_increments\n",
    "\n",
    "    \n",
    "def globalavgpooling2d_conversion(config, name, verbose, **kwargs):\n",
    "    return [layers.GlobalAvgPool2D(name=name, verbose=verbose)]\n",
    "\n",
    "    \n",
    "class ZeroPadding2D(NoOp):\n",
    "    def __init__(self, padding, data_format=None, **kwargs):                \n",
    "        # self.rank is 1 for ZeroPadding1D, 2 for ZeroPadding2D.            \n",
    "        self.rank = len(padding)                                            \n",
    "        self.padding = padding                                              \n",
    "        self.data_format = K.normalize_data_format(data_format)             \n",
    "        super(ZeroPadding2D, self).__init__(**kwargs)                       \n",
    "                                                                            \n",
    "    def _compute_shape(self, input_shape):                                  \n",
    "        padding_all_dims = ((0, 0),) + tuple(self.padding) + ((0, 0),)\n",
    "        spatial_axes = list(range(1, 1 + self.rank))           \n",
    "        padding_all_dims = transpose_shape(padding_all_dims,    \n",
    "                                           self.data_format,    \n",
    "                                           spatial_axes)        \n",
    "        output_shape = list(input_shape)                       \n",
    "        for dim in range(len(output_shape)):                    \n",
    "            if output_shape[dim] is not None:                   \n",
    "                output_shape[dim] += sum(padding_all_dims[dim]) \n",
    "        print(\"ZeroPadding\", input_shape, output_shape, self.padding)\n",
    "        return tuple(output_shape)                                          \n",
    "                                                                            \n",
    "    def _build_activation_vars(self, inputs):                               \n",
    "        return K.spatial_2d_padding(inputs,                                 \n",
    "                                    padding=self.padding,                   \n",
    "                                    data_format=self.data_format) \n",
    "\n",
    "    def _build_pos_and_neg_contribs(self):\n",
    "        input_pos_contribs, input_neg_contribs = self._get_input_pos_and_neg_contribs()\n",
    "        return (self._build_activation_vars(input_pos_contribs), \n",
    "                self._build_activation_vars(input_neg_contribs))\n",
    "        \n",
    "    def _grad_op(self, out_grad):\n",
    "        b, h, w, c = self._get_input_activation_vars().get_shape().as_list()\n",
    "        print(\"ZeroPadding2D\", self.padding)\n",
    "        (ha, hb), (wa, wb) = self.padding\n",
    "        return out_grad[:, ha:ha+h, wa:wa+w]\n",
    "    \n",
    "    def _get_mxts_increments_for_inputs(self):\n",
    "        pos_mxts_increments = self._grad_op(self.get_pos_mxts())\n",
    "        neg_mxts_increments = self._grad_op(self.get_neg_mxts())\n",
    "        return pos_mxts_increments, neg_mxts_increments\n",
    "\n",
    "    \n",
    "def globalavgpooling2d_conversion(config, name, verbose, **kwargs):\n",
    "    return [GlobalAvgPool2D(\n",
    "             name=name,\n",
    "             verbose=verbose)]\n",
    "\n",
    "\n",
    "def zeropadding2d_conversion(config, name, verbose, **kwargs):                         \n",
    "    #print(config, name, verbose, kwargs)                                              \n",
    "    padding = config[KerasKeys.padding]                                                \n",
    "    data_format = config[KerasKeys.data_format]                                        \n",
    "    return [ZeroPadding2D(padding, data_format)]  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Add(Dense):                                                  \n",
    "    \"\"\"                                                            \n",
    "    Is like a linear layer: [1 1] * [a b]^T                        \n",
    "    \"\"\"                                                            \n",
    "    def __init__(self, **kwargs):         \n",
    "        super(Add, self).__init__(                                 \n",
    "            kernel=np.ones((2, 1)),                               \n",
    "            bias=np.zeros((1,)),                                   \n",
    "            dense_mxts_mode=DenseMxtsMode.Linear, **kwargs)        \n",
    "\n",
    "        \n",
    "class ConcatForAdd(Concat):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(axis=4, **kwargs)\n",
    "        \n",
    "    def _build_activation_vars(self, input_act_vars):\n",
    "        return super()._build_activation_vars([v[:, :, :, :, None] for v in input_act_vars])\n",
    " \n",
    "    def _compute_shape(self, input_shape):\n",
    "        input_shape_pad = [list(inp) + [1,] for inp in input_shape]\n",
    "        output_shape = super()._compute_shape(input_shape_pad)\n",
    "        return output_shape\n",
    "    #def _build_pos_and_neg_contribs(self):\n",
    "    #    pos, neg = super()._build_pos_and_neg_contribs()\n",
    "    #    return [p[:, :, :, :, 0] for p in pos], [n[:, :, :, :, 0] for n in neg]\n",
    "    \n",
    "    def _get_mxts_increments_for_inputs(self):\n",
    "        print(\"ConcatForAdd: MXTS inc\")\n",
    "        pos, neg = super()._get_mxts_increments_for_inputs()\n",
    "        print(pos.shape, neg.shape)\n",
    "        return [p[:, :, :, :, 0] for p in pos], [n[:, :, :, :, 0] for n in neg]\n",
    "\n",
    "    def _get_mxts_increments_for_inputs(self):                                  \n",
    "        return (\n",
    "            [self.get_pos_mxts()[:, :, :, :, i] for i in range(len(self.inputs))],\n",
    "            [self.get_neg_mxts()[:, :, :, :, i] for i in range(len(self.inputs))],\n",
    "        )\n",
    "    \n",
    "    \n",
    "class FlattenForAdd(NoOp):\n",
    "    def _compute_shape(self, input_shape):                         \n",
    "        b, h, w, c, n = input_shape             \n",
    "        if b is None:\n",
    "            warnings.warn(\"Assume batch_size = 1\")\n",
    "            b = 1\n",
    "        self.shape_tuple = (None, h, w, c)\n",
    "        return (None, n)                                     \n",
    "    \n",
    "    def _build_activation_vars(self, input_act_vars):              \n",
    "        shape = input_act_vars.shape                               \n",
    "        self.shape_tensor = tf.shape(input_act_vars)\n",
    "        return tf.reshape(input_act_vars, (-1, shape[-1]))\n",
    "\n",
    "    def _get_mxts_increments_for_inputs(self):              \n",
    "        input_shape = tf.shape(self.inputs._activation_vars)\n",
    "        print(input_shape)\n",
    "        pos_mxts_increments = tf.reshape(self.get_pos_mxts(), input_shape)\n",
    "        neg_mxts_increments = tf.reshape(self.get_neg_mxts(), input_shape)             \n",
    "        return pos_mxts_increments, neg_mxts_increments       \n",
    "    \n",
    "class BackToConvForAdd(NoOp):\n",
    "    def __init__(self, corresponding_flatten, **kwargs):\n",
    "        self.corresponding_flatten = corresponding_flatten\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def _compute_shape(self, input_shape):\n",
    "        return self.corresponding_flatten.shape_tuple\n",
    "    \n",
    "    def _build_activation_vars(self, input_act_vars):\n",
    "        print(\"BackToConvForAdd\", self.corresponding_flatten.shape_tensor)\n",
    "        out = tf.reshape(input_act_vars, self.corresponding_flatten.shape_tensor[:-1])\n",
    "        return out\n",
    "    \n",
    "    def _build_pos_and_neg_contribs(self):\n",
    "        inp_pos_contribs, inp_neg_contribs = self._get_input_pos_and_neg_contribs()                  \n",
    "        pos_contribs = self._build_activation_vars(inp_pos_contribs)\n",
    "        neg_contribs = self._build_activation_vars(inp_neg_contribs)\n",
    "        return pos_contribs, neg_contribs                           \n",
    "                                                                    \n",
    "    def _unflatten_keeping_first(self, mxts):                       \n",
    "        input_act_vars = self._get_input_activation_vars()          \n",
    "        print(\"BackToConvForAdd _unflatten\", tf.shape(input_act_vars))\n",
    "        return tf.reshape(tensor=mxts,                              \n",
    "                          shape=tf.shape(input_act_vars))           \n",
    "                                                                    \n",
    "    def _get_mxts_increments_for_inputs(self):              \n",
    "        input_shape = tf.shape(self.inputs._activation_vars)\n",
    "        print(input_shape)\n",
    "        pos_mxts_increments = tf.reshape(self.get_pos_mxts(), (-1, 1))\n",
    "        neg_mxts_increments = tf.reshape(self.get_neg_mxts(), (-1, 1))             \n",
    "        return pos_mxts_increments, neg_mxts_increments       \n",
    "        \n",
    "        \n",
    "def add_conversion(config, name, verbose, **kwargs):               \n",
    "    #print(config, name, verbose, kwargs)    \n",
    "    flatten = FlattenForAdd() \n",
    "    return deeplift.util.connect_list_of_layers([ConcatForAdd(), flatten, Add(), BackToConvForAdd(flatten)])\n",
    "    #return deeplift.util.connect_list_of_layers([ConcatForAdd(), flatten, Add(), BackToConvForAdd(flatten)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from deeplift.conversion.kerasapi_conversion import layer_name_to_conversion_function as deeplift_layer_name_to_conversion_function\n",
    "\n",
    "if 'copy_layer_name_to_conversion_function' not in globals():\n",
    "    copy_layer_name_to_conversion_function = copy.deepcopy(deeplift_layer_name_to_conversion_function)\n",
    "    \n",
    "def monkey_patched_layer_name_to_conversion_function(layer_name):  \n",
    "    try: \n",
    "        return copy_layer_name_to_conversion_function(layer_name)\n",
    "    except KeyError:\n",
    "        return {\n",
    "           'zeropadding2d': zeropadding2d_conversion,                                                                                                                                                                                                                              \n",
    "           'globalaveragepooling2d': globalavgpooling2d_conversion,                                                                                                                                                                                                                              \n",
    "           'add': add_conversion,                 \n",
    "       }[layer_name.lower()]\n",
    "    \n",
    "deeplift.conversion.kerasapi_conversion.layer_name_to_conversion_function = \\\n",
    "    monkey_patched_layer_name_to_conversion_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlinear_mode  = 'rescale'  # or reveal_cancel\n",
    "nonlinear_mode  = 'reveal_cancel'\n",
    "\n",
    "dl_original = innvestigate.analyzer.DeepLIFTWrapper(model_cascading, nonlinear_mode=nonlinear_mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb off\n",
    "hmap_original = dl_original.analyze(ex_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_model = dl_original._deeplift_model\n",
    "dp_layers = dp_model._name_to_layer\n",
    "dp_layer_names = list(dp_layers.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(dp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deeplift_prediction(dp_model, output_layer=None):\n",
    "    inp_layer_name = dp_model._input_layer_names[0]\n",
    "    inp_layer = dp_model._name_to_layer[inp_layer_name]\n",
    "    if output_layer is None:\n",
    "        output_layer = list(dp_model._name_to_layer.values())[-1]\n",
    "    \n",
    "    outputs = output_layer.get_activation_vars()\n",
    "    def wrapper(inp_val, ref_val):\n",
    "        sess = K.get_session()\n",
    "        return sess.run([outputs], feed_dict={\n",
    "            inp_layer.get_activation_vars(): inp_val,\n",
    "            inp_layer.get_reference_vars(): ref_val,\n",
    "        })[0]\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_predition_func = deeplift_prediction(dp_model)\n",
    "out_deeplift = dp_predition_func(ex_image, np.zeros_like(ex_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_deeplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_keras = model_cascading.predict(ex_image)\n",
    "np.abs(out_deeplift - out_keras).mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(out_deeplift - out_keras).max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_original._deeplift_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hmap_original[0].sum(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2_1 = list(dp_layers.values())[6]\n",
    "input_layer = list(dp_layers.values())[0]\n",
    "target_layer = list(dp_layers.values())[-1]\n",
    "target_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer.get_activation_vars(), input_layer.get_reference_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_layer._diff_from_reference_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2_1._get_input_diff_from_reference_vars() == list(dp_layers.values())[5]._diff_from_reference_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conv2_1._diff_from_reference_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to handle different layer idxs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLiftCSC:\n",
    "    def __init__(self, deeplift_wrapper):\n",
    "        self.deeplift_wrapper = deeplift_wrapper\n",
    "        self.model = self.deeplift_wrapper._deeplift_model\n",
    "        self.layers = list(self.model._name_to_layer.values())\n",
    "        self.layer_names = list(self.model._name_to_layer.keys())\n",
    "        self.input_layer = self.layers[0]\n",
    "        \n",
    "    def get_relevances(self, input_value, set_layer_idx, relevance_value, reference=None):\n",
    "        if reference is None:\n",
    "            reference = np.zeros_like(input_value)\n",
    "            \n",
    "        self.layers[-1].set_active()\n",
    "        changed_layer = self.layers[set_layer_idx]\n",
    "        sess = keras.backend.get_session()\n",
    "        contribs = sess.run(\n",
    "            [layer._pos_mxts for layer in self.layers[:set_layer_idx]], \n",
    "            #[layer._pos_mxts for layer in self.layers[:set_layer_idx]], \n",
    "            feed_dict={\n",
    "                self.input_layer.get_activation_vars(): ex_image,\n",
    "                self.input_layer.get_reference_vars(): np.zeros_like(ex_image),\n",
    "                changed_layer._pos_mxts: relevance_value,\n",
    "                changed_layer._neg_mxts: relevance_value,\n",
    "        })\n",
    "        return contribs\n",
    "\n",
    "    \n",
    "class ModifyWeights:\n",
    "    def __init__(self, model_trained, model_random, model):\n",
    "        pass\n",
    "    \n",
    "    def copy_trained(self, layer_idxs=None):\n",
    "        pass\n",
    "    \n",
    "    def copy_random(self, layer_idxs=None):\n",
    "        pass\n",
    "\n",
    "\n",
    "class DeepLiftModifyWeights(ModifyWeights):\n",
    "    def __init__(self, model_trained, model_random):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_csc = DeepLiftCSC(dl_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dl_csc.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dl_csc.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_cascading.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 1\n",
    "cols = 5\n",
    "\n",
    "s = 5\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(s*cols, s*rows))\n",
    "\n",
    "rel_multi = []\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    n_sampels = 1\n",
    "    rel_val = np.random.normal(size=(n_sampels, 1000)) \n",
    "    rel_val /= np.linalg.norm(rel_val)\n",
    "    rel_per_layer = dl_csc.get_relevances(\n",
    "        np.repeat(ex_image, n_sampels, axis=0),  set_layer_idx=159, \n",
    "        relevance_value=rel_val)\n",
    "    \n",
    "    im = ax.imshow(normalize(rel_per_layer[0][0].sum(-1)))\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    rel_multi.append(rel_per_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_dot(U, V):\n",
    "    v_norm =  V / np.linalg.norm(V, axis=1, keepdims=True)\n",
    "    u_norm = U / np.linalg.norm(U, axis=1, keepdims=True)\n",
    "    return (v_norm * u_norm).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.uniform(size=(10, 5))\n",
    "b = np.random.uniform(size=(10, 5))\n",
    "cosine_similarity_dot(a, b).shape\n",
    "cosine_similarity_dot(a, b),  cosine_similarity_dot(a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total relevance for 1 sample in MB:\", sum([rel.size * 4 for rel in rel_per_layer]) / 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "for idx in range(0, 30):\n",
    "    for i, j in itertools.combinations(range(len(rel_multi)), 2):\n",
    "        b, h, w, c = rel_multi[i][idx].shape\n",
    "        cos = cosine_similarity_dot(rel_multi[i][idx].reshape(b*h*w, c), rel_multi[j][idx].reshape(b*h*w, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(0, 30):\n",
    "#idx = 30\n",
    "    \n",
    "    try:\n",
    "        b, h, w, c = rel_multi[0][idx].shape\n",
    "        print(rel_multi[0][idx].reshape(b*h*w, c).shape)\n",
    "        cos = cosine_similarity_dot(rel_multi[0][idx].reshape(b*h*w, c), rel_multi[1][idx].reshape(b*h*w, c))\n",
    "        print(cos.shape)\n",
    "        _ = plt.hist(cos.flatten(), bins=40) #, range=[0.99, 1])\n",
    "        plt.title(idx)\n",
    "        plt.show()\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(0, 30):\n",
    "    try:\n",
    "        b, h, w, c = rel_multi[0][idx].shape\n",
    "        cos = cosine_similarity(rel_multi[0][idx].reshape(b*h*w, c), rel_multi[1][idx].reshape(b*h*w, c))\n",
    "        _ = plt.hist(cos.flatten(), bins=40, range=[-1, 1])\n",
    "        plt.title(idx)\n",
    "        plt.show()\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_multi[0][30] - rel_multi[1][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rel_per_layer[0] == 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_per_layer[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rel_per_layer[1][0].sum(-1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(rel_per_layer[0][0].sum(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sess = keras.backend.get_session()\n",
    "dp_model._set_scoring_mode_for_target_layer(target_layer)\n",
    "target_layer.set_active()\n",
    "\n",
    "contrib = sess.run([input_layer.get_target_contrib_vars()], {\n",
    "    input_layer.get_activation_vars(): ex_image,\n",
    "    input_layer.get_reference_vars(): np.zeros_like(ex_image),\n",
    "    conv2_1._get_input_diff_from_reference_vars(): 200*np.random.normal(size=(1, 112, 112, 64)),\n",
    "    #conv2_1._pos_contribs: -50*np.ones(shape=(1, 112, 112, 128)),\n",
    "    #conv2_1._neg_contribs: -50*np.ones(shape=(1, 112, 112, 128)),\n",
    "    #conv2_1._pos_contribs: np.random.normal(size=(1, 112, 112, 128)),\n",
    "    #conv2_1._neg_contribs: np.random.normal(size=(1, 112, 112, 128)),\n",
    "    #conv2_1._diff_from_reference_vars: np.random.normal(size=(1, 112, 112, 128)),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(contrib[0][0].sum(-1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(contrib_a[0][0].sum(-1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelModifier:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def copy_weights(self, other_model, layer_indices):\n",
    "        copy_weights(self.model, other_model, layer_indices)\n",
    "    \n",
    "    def get_relevances(self, set_relevances_to=None, set_at_layer=None):\n",
    "        pass\n",
    "    \n",
    "    def get_layer_idx(self, name):\n",
    "        pass\n",
    "    \n",
    "    def get_layer_name(self, idx):\n",
    "        pass\n",
    "    \n",
    "    def get_output_shape(self, layer_idx):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(normalize(contrib_a[0]) - normalize(contrib[0])).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(contrib[0][0].sum(-1) - contrib_a[0][0].sum(-1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(dp_layers.keys())[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_all = dl_original._deeplift_model._get_func(\n",
    "    find_scores_layer_name=[n for (n, _) in layers],\n",
    "    pre_activation_target_layer_name=layers[-1][0],\n",
    "    func_type=deeplift.models.FuncType.contribs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribs_per_layer = func_all(input_data_list=[ex_image], batch_size=1, progress_update=1, task_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(contribs_per_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.maximum(0, contribs_per_layer[9][0]).sum(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.minimum(0, contribs_per_layer[9][0]).sum(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for contrib in contribs_per_layer:\n",
    "    print(contrib[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dl_original._deeplift_model._get_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers  = list("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.backend.get_session()\n",
    "\n",
    "sess.run([\n",
    "    layer._pos_contribs, layer._neg_contribs\n",
    "], feed_dict={\n",
    "    \n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "hmap_original = dl_original.analyze(ex_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(dl_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks on one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlinear_mode  = 'rescale'  # or reveal_cancel\n",
    "copy_weights(model_cascading, model, range(0, original_idx))\n",
    "dl_original = innvestigate.analyzer.DeepLIFTWrapper(model_cascading, nonlinear_mode=nonlinear_mode)\n",
    "out_original = model_cascading.predict(ex_image)\n",
    "hmap_original = dl_original.analyze(ex_image)\n",
    "\n",
    "\n",
    "copy_weights(model_cascading, model_random, range(layer_idx, original_idx))\n",
    "out_random = model_cascading.predict(ex_image)\n",
    "\n",
    "dl_random = innvestigate.analyzer.DeepLIFTWrapper(model_cascading, nonlinear_mode=nonlinear_mode)\n",
    "hmap_random = dl_random.analyze(ex_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('logit l1-mean:',  np.abs(out_original - out_random).mean())\n",
    "\n",
    "plt.imshow(hmap_original[0].sum(-1))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(hmap_random[0].sum(-1))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(hmap_original[0].sum(-1) - hmap_random[0].sum(-1))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlinear_mode  = 'reveal_cancel'\n",
    "copy_weights(model_cascading, model, range(0, original_idx))\n",
    "dl_original = innvestigate.analyzer.DeepLIFTWrapper(model_cascading, nonlinear_mode=nonlinear_mode)\n",
    "out_original = model_cascading.predict(ex_image)\n",
    "hmap_original = dl_original.analyze(ex_image)\n",
    "\n",
    "\n",
    "copy_weights(model_cascading, model_random, range(layer_idx, original_idx))\n",
    "out_random = model_cascading.predict(ex_image)\n",
    "\n",
    "dl_random = innvestigate.analyzer.DeepLIFTWrapper(model_cascading, nonlinear_mode=nonlinear_mode)\n",
    "hmap_random = dl_random.analyze(ex_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('logit l1-mean:',  np.abs(out_original - out_random).mean())\n",
    "\n",
    "plt.imshow(hmap_original[0].sum(-1))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.imshow(hmap_random[0].sum(-1))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(hmap_original[0].sum(-1) - hmap_random[0].sum(-1))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonlinear_mode  = rescale or reveal_cancel\n",
    "copy_weights(model_cascading, model, range(0, original_idx))\n",
    "dl_original = innvestigate.analyzer.DeepLIFTWrapper(model_cascading, nonlinear_mode='reveal_cancel')\n",
    "\n",
    "\n",
    "copy_weights(model_cascading, model_random, range(layer_idx, original_idx))\n",
    "# nonlinear_mode  = rescale or reveal_cancel\n",
    "dl_random = innvestigate.analyzer.DeepLIFTWrapper(model_cascading, nonlinear_mode='reveal_cancel')\n",
    "\n",
    "\n",
    "hmap_original = dl_original.analyze(ex_image)\n",
    "hmap_random = dl_random.analyze(ex_image)\n",
    "\n",
    "\n",
    "plt.imshow(hmap_original[0].sum(-1))\n",
    "plt.imshow(hmap_random[0].sum(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(out_original - out_random).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(hmap_original[0].sum(-1))\n",
    "plt.show()\n",
    "plt.imshow(hmap_random[0].sum(-1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmap_original - hmap_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "hmap_random = dl_random.analyze(ex_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "hmap = dl.analyze(ex_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self._func(task_idx=neuron_idx,\n",
    "           input_data_list=X,\n",
    "           batch_size=batch_size,\n",
    "           input_references_list=self._references,\n",
    "           progress_update=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hmap[0].sum(-1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hmap[0].sum(-1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_reversed(hidden):\n",
    "    return [h[1] for h in hidden[1:]]\n",
    "\n",
    "\n",
    "dead_neuron_mask = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    keras.backend.clear_session()\n",
    "    model, innv_net, _ = load_model(model_name, load_weights=True)\n",
    "    analyser = innvestigate.create_analyzer(\n",
    "        \"gradient\", model, reverse_keep_tensors=True)\n",
    "    \n",
    "    analyser.analyze(np.concatenate([img for (img, _) in val_images[:20]], 0))\n",
    "    \n",
    "    grad_hidden = parse_reversed(analyser._reversed_tensors) \n",
    "    dead_neuron_mask[model_name] = [(0 == np.mean(g, 0, keepdims=True)).all(-1, keepdims=True) for g in grad_hidden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    plt.title(model_name + \" - active neurons\")\n",
    "    plt.plot([(m.sum(-1) / m.shape[-1] > 0.999999).mean() for m in dead_neuron_mask[model_name]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice_layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_layers = copy.deepcopy(replacement_layers)\n",
    "histogram_layers['vgg16'].extend(['conv1_1', 'input'])\n",
    "histogram_layers['resnet50'].extend(['conv2_1a', 'input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "histogram_layers_idx = OrderedDict()\n",
    "for model_name in model_names:\n",
    "    histogram_layers_idx[model_name] = []\n",
    "    for layer_name in histogram_layers[model_name]:\n",
    "        idx = get_layer_idx_full(model_name, nice_layer_names, layer_name)\n",
    "        histogram_layers_idx[model_name].append(idx) \n",
    "histogram_layers_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dead_neuron_mask['vgg16'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from innvestigate.analyzer.relevance_based.relevance_rule import AlphaBetaRule\n",
    "\n",
    "def alpha_beta_wrapper(alpha, beta):\n",
    "    class AlphaBetaRuleWrapper(AlphaBetaRule):\n",
    "        def __init__(self, layer, state, bias=True, copy_weights=False):\n",
    "            super(AlphaBetaRuleWrapper, self).__init__(layer, state, alpha=alpha, beta=beta, \n",
    "                             bias=bias, copy_weights=copy_weights)\n",
    "            \n",
    "        def __repr__(self):\n",
    "            return \"AlphaBetaRuleWrapper(alpha={}, beta={})\".format(self._alpha, self._beta)\n",
    "        \n",
    "    return AlphaBetaRuleWrapper\n",
    "\n",
    "def get_custom_rule(innv_name, kwargs):\n",
    "    if innv_name == 'lrp.alpha_beta':\n",
    "        return alpha_beta_wrapper(kwargs['alpha'], kwargs['beta'])\n",
    "    elif innv_name == 'lrp.sequential_preset_a':\n",
    "        return alpha_beta_wrapper(1, 0)\n",
    "    elif innv_name == 'lrp.sequential_preset_b':\n",
    "        return alpha_beta_wrapper(2, 1)\n",
    "        \n",
    "for label, innv_name, _, excludes, kwargs in analysers:\n",
    "    print(innv_name, get_custom_rule(innv_name, kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_layers= {'vgg16': ['fc3'], 'resnet50': ['dense']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names, replacement_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacement_layer_indices = [22]\n",
    "n_sampled_v = 5\n",
    "\n",
    "cos_sim_histograms = {}\n",
    "cos_mean = {}\n",
    "selected_percentiles = [0, 1, 5, 10, 20, 50, 100]\n",
    "cos_sim_percentiles = {}\n",
    "\n",
    "for label, innv_name, _, excludes, kwargs in tqdm.tqdm_notebook(analysers[4:]):\n",
    "    if 'exclude_cos_sim' in excludes:\n",
    "        continue\n",
    "    for model_name in model_names[:1]:\n",
    "        if 'exclude_' + model_name in excludes:\n",
    "            continue\n",
    "        keras.backend.clear_session()\n",
    "        model_wo_softmax, innv_net, _ = load_model(model_name, load_weights=load_weights)\n",
    "        if innv_name == \"pattern.attribution\":\n",
    "            kwargs['patterns'] = innv_net['patterns']\n",
    "\n",
    "        for replacement_layer in replacement_layers[model_name]:\n",
    "            replacement_layer_idx = get_layer_idx_full(model_name, nice_layer_names, replacement_layer)\n",
    "            custom_rule = get_custom_rule(innv_name, kwargs)\n",
    "            with custom_add_bn_rule(custom_rule):\n",
    "                repl_analyser, repl_shape = get_replacement_analyser(\n",
    "                    model_wo_softmax, innv_name,  \n",
    "                    replacement_layer_idx=replacement_layer_idx,\n",
    "                    **kwargs)\n",
    "                # repl_analyser.create_analyzer_model()\n",
    "                cos_per_img = OrderedDict()\n",
    "                for img_idx, (img, _) in tqdm.tqdm_notebook(zip(selected_img_idxs, val_images), \n",
    "                    desc=\"[{}.{}] {}\".format(model_name, replacement_layer, label)):\n",
    "                    channels = repl_shape[-1]\n",
    "                    if label == \"$\\\\alpha=100, \\\\beta=99$-LRP\":\n",
    "                        # a=100,b=99 sufferes numerical instabilities with std = 1\n",
    "                        std = 1 / np.sqrt(channels)\n",
    "                    else:\n",
    "                        std = 1\n",
    "\n",
    "                    relevance_v1 = std*np.random.normal(size=(1, ) + repl_shape[1:]) \n",
    "                    hmap = repl_analyser.analyze([img, relevance_v1])\n",
    "                    intermediate_values = parse_reversed(repl_analyser._reversed_tensors)\n",
    "\n",
    "                    relevance_v2 = std * np.random.normal(size=(n_sampled_v,) + repl_shape[1:]) \n",
    "                    img_tiled = np.tile(img, (n_sampled_v, 1, 1, 1))\n",
    "                    outs = repl_analyser.get_cosine(img_tiled, relevance_v2,  intermediate_values[::-1])\n",
    "                    outs = outs[::-1]\n",
    "                    for layer_idx, (o, dead_neuron) in enumerate(zip(outs, dead_neuron_mask[model_name])):\n",
    "                        cos_for_layer = np.abs(o)\n",
    "                        # we filter 0 cosine similarites as they only appear practically when the gradients are zero\n",
    "                        cos_per_img[model_name, layer_idx, img_idx] = cos_for_layer[cos_for_layer != 0]\n",
    "\n",
    "                median_for_label = []\n",
    "                percentile_for_label = OrderedDict([(p, []) for p in selected_percentiles])\n",
    "                for layer_idx in range(n_layers[model_name]):\n",
    "                    cos_per_layer = np.concatenate([cos_per_img[model_name, layer_idx, img_idx]  for img_idx in selected_img_idxs])\n",
    "                    cos_per_layer = cos_per_layer.flatten()\n",
    "\n",
    "                    idx = (label, model_name, replacement_layer_idx,  layer_idx)\n",
    "                    cos_mean[idx] = np.mean(cos_per_layer)\n",
    "\n",
    "                    perc_values = np.percentile(cos_per_layer,  selected_percentiles)\n",
    "                    for p, val in zip(selected_percentiles, perc_values):\n",
    "                        percentile_for_label[p].append(val)\n",
    "\n",
    "                    if layer_idx in histogram_layers_idx[model_name]:\n",
    "\n",
    "                        if len(cos_per_layer) > 50000:\n",
    "                            ridx = np.random.choice(len(cos_per_layer), 50000, replace=False)\n",
    "                            cos_per_layer_sel = cos_per_layer[ridx]\n",
    "                        else:\n",
    "                            cos_per_layer_sel = cos_per_layer\n",
    "\n",
    "                        cos_sim_histograms[idx] = np.histogram(cos_per_layer_sel, bins)\n",
    "\n",
    "\n",
    "                for p, values in percentile_for_label.items():\n",
    "                    cos_sim_percentiles[label, model_name, replacement_layer_idx, p] = np.array(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with keras.backend.get_session().as_default():\n",
    "    print(1 - tf.losses.cosine_distance([0, 0], [0, 0], 0).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs[0].shape, outs[-4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = False\n",
    "if save_results:\n",
    "    os.makedirs('cache', exist_ok=True)\n",
    "    with open('cache/cos_sim_with_hist_random_weights.pickle', 'wb') as f:\n",
    "        pickle.dump((cos_sim_percentiles, cos_sim_histograms ), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_results = False\n",
    "if load_results:\n",
    "    os.makedirs('cache', exist_ok=True)\n",
    "    with open('cache/cos_sim_with_hist.pickle', 'rb') as f:\n",
    "        cos_sim_percentiles, cos_sim_histograms = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(U, V):\n",
    "    v_norm = V / np.linalg.norm(V, axis=0, keepdims=True)\n",
    "    u_norm = U / np.linalg.norm(U, axis=0, keepdims=True)\n",
    "    return v_norm.T @ u_norm\n",
    "\n",
    "def get_sample_cos_sim_per_layer(output_shapes):\n",
    "    values = []\n",
    "    for layer_idx, shp in output_shapes.items():\n",
    "        ch = shp[-1]\n",
    "        n_samples = 1000\n",
    "        u = np.random.normal(size=(ch, n_samples))\n",
    "        v = np.random.normal(size=(ch, n_samples))\n",
    "        cos = cosine_similarity(v, u)\n",
    "        mask = np.tri(cos.shape[0])\n",
    "        values.append(np.median(np.abs(cos[mask == 1])))\n",
    "    return np.array(values)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_baseline = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    keras.backend.clear_session()\n",
    "    model, _, _ = load_model(model_name)\n",
    "    output_shapes = get_output_shapes(model)\n",
    "    print(len(output_shapes))\n",
    "    cos_sim_baseline[model_name] = get_sample_cos_sim_per_layer(output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_baseline['vgg16'].shape, cos_sim_baseline['resnet50'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = OrderedDict()\n",
    "\n",
    "os.makedirs('figures/cosine_similarity', exist_ok=True)\n",
    "for model_name in model_names[::-1]:\n",
    "    for replacement_layer in replacement_layers[model_name]:\n",
    "        repl_idx = get_layer_idx_full(model_name, nice_layer_names, replacement_layer)\n",
    "        start_layer = n_layers[model_name] - repl_idx \n",
    "        \n",
    "        layer_names = [name for idx, name in nice_layer_names[model_name].items()\n",
    "                       if idx <= repl_idx][::-1]\n",
    "        layer_idx = np.array([idx for idx, name in nice_layer_names[model_name].items()\n",
    "                       if idx < repl_idx][::-1])\n",
    "        \n",
    "        print(layer_idx, repl_idx, start_layer)\n",
    "        #layer_idx = layer_idxs\n",
    "        \n",
    "        plt.figure(figsize=(max(3, len(layer_idx) / 4), 3.5))\n",
    "        \n",
    "        for i, (label, _, _, _, _) in enumerate(analysers):\n",
    "            idx = (label, model_name, repl_idx, 50)\n",
    "            if idx not in cos_sim_percentiles:\n",
    "                warnings.warn(\"not found: \" + str(idx))\n",
    "                continue\n",
    "            print(len(cos_sim_percentiles[idx]))\n",
    "            cos_sim_per_label = cos_sim_percentiles[idx][layer_idx]\n",
    "            \n",
    "            #cos_sim_per_label = []\n",
    "            #for lidx in layer_idx:\n",
    "            #    cos_sim_per_label.append(cos_mean[label, model_name, repl_idx, lidx])\n",
    "            # try:\n",
    "            #     cos_sim_per_label = cos_sim_percentiles[idx][layer_idx]\n",
    "            # except IndexError:\n",
    "            #     cos_sim_per_label = (cos_sim_baseline[model_name][layer_idx[:1]].tolist() +\n",
    "            #                          cos_sim_percentiles[idx][layer_idx[1:]].tolist())\n",
    "                \n",
    "            plt.plot(0.5 + np.arange(len(cos_sim_per_label)), cos_sim_per_label, label=label, **mpl_styles[label])\n",
    "            \n",
    "            if label not in legend:\n",
    "                legend[label] = mpl_styles[label]\n",
    "            \n",
    "        # Random Cos Similarity\n",
    "        # Cos Similarity Base.\n",
    "        label='Cos Similarity BL'\n",
    "        style = {'color': (0.25, 0.25, 0.25)}\n",
    "        plt.plot(0.5 + np.arange(len(layer_idx)), cos_sim_baseline[model_name][layer_idx], \n",
    "                 # label='Cos. Sim. Baseline', \n",
    "                 label=label,\n",
    "                 **style)\n",
    "        if label not in legend:\n",
    "            legend[label] = style\n",
    "        \n",
    "        #plt.legend(bbox_to_anchor=(1, 1))\n",
    "        plt.ylabel('cosine similarity')\n",
    "        plt.xticks(np.arange(len(layer_names)), layer_names, rotation=90)\n",
    "        plt.ylim(-0.05, 1.05)\n",
    "        plt.grid('on', alpha=0.35) #, axis=\"y\")\n",
    "        plt.savefig(\"./figures/cosine_similarity/{}_layer_{}.pdf\".format(model_name, repl_idx),  \n",
    "                    bbox_inches='tight', pad_inches=0)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(cos_mean.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.5, 3))\n",
    "for label, style in legend.items():\n",
    "    plt.plot([], label=label, alpha=1, **style)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.legend(loc='center')\n",
    "plt.savefig(\"./figures/cos_sim_legend.pdf\",\n",
    "            bbox_inches='tight', pad_inches=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(IFrame(\"./figures/cos_sim_legend.pdf\", 800, 600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr_name, model_name, layer_idx, percentile in cos_sim_percentiles.keys():\n",
    "    if attr_name == 'GuidedBP' and model_name == 'resnet50':\n",
    "        print(attr_name, model_name, layer_idx, percentile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_histograms.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "attr_counts = []\n",
    "labels = []\n",
    "for (attr_name, model_name, repl_layer, layer_idx), (counts, bins) in cos_sim_histograms.items():\n",
    "    if layer_idx != 7:\n",
    "        #print(layer_idx)\n",
    "        continue\n",
    "    lower_09 = counts[bins[:-1] < 0.9].sum()\n",
    "    print(attr_name, counts.sum())\n",
    "    counts_collapsed = np.concatenate([lower_09[None], counts[bins[:-1] >= 0.9]])\n",
    "    bins_int = np.arange(len(counts_collapsed) + 1)\n",
    "    attr_counts.append(counts_collapsed)\n",
    "    labels.append(attr_name)\n",
    "plt.hist([bins_int[:-1]] * len(attr_counts), bins_int, \n",
    "         weights=attr_counts, stacked=True, label=labels)\n",
    "plt.xticks(bins_int, [\"{:.4g}\".format(b) for b in [0] + bins[bins >= 0.9].tolist()], rotation=0)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
