{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When Explanations Lie: Why Modified BP Attribution fails\n",
    "\n",
    "This notebook produces the cosine similaries of the relevance vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to install install packages\n",
    "# !pip install tensorflow-gpu==1.13.1\n",
    "# !pip install innvestigate seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "\n",
    "import innvestigate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import PIL \n",
    "import copy\n",
    "import contextlib\n",
    "\n",
    "import imp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from skimage.measure import compare_ssim \n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from IPython.display import IFrame, display\n",
    "\n",
    "import keras\n",
    "import keras.backend\n",
    "import keras.models\n",
    "\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.applications.imagenet\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "from innvestigate.analyzer.relevance_based.relevance_analyzer import LRP\n",
    "from innvestigate.analyzer.base import AnalyzerNetworkBase, ReverseAnalyzerBase\n",
    "from innvestigate.analyzer.deeptaylor import DeepTaylor\n",
    "\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "from when_explanations_lie import *\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_model(self, model):\n",
    "    return super(DeepTaylor, self)._prepare_model(model)\n",
    "\n",
    "# otherwise DTD does not work on negative outputs\n",
    "DeepTaylor._prepare_model = _prepare_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to imagenet validation\n",
    "imagenet_val_dir = \"/mnt/ssd/data/imagenet/imagenet-raw/validation\"\n",
    "#imagenet_val_dir = \"/home/leonsixt/tmp/imagenet/imagenet-raw/validation/\"\n",
    "# path to examplary image\n",
    "ex_image_path = \"n01534433/ILSVRC2012_val_00015410.JPEG\"\n",
    "# number of images to run the evaluation\n",
    "#n_selected_imgs = 200\n",
    "n_selected_imgs = 10\n",
    "\n",
    "load_weights = True\n",
    "model_names = ['resnet50', 'vgg16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.backend.clear_session()\n",
    "#model, innv_net, color_conversion = load_model('vgg16', load_weights)\n",
    "#ex_image_vgg, ex_target, val_images, selected_img_idxs = load_val_images(\n",
    "#    innv_net, imagenet_val_dir, ex_image_path, n_selected_imgs)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "model, innv_net, color_conversion = load_model('resnet50', load_weights)\n",
    "ex_image, ex_target, val_images, selected_img_idxs = load_val_images(\n",
    "    innv_net, imagenet_val_dir, ex_image_path, n_selected_imgs)\n",
    "\n",
    "\n",
    "#assert ((ex_image - ex_image_vgg) == 0).all()\n",
    "\n",
    "nice_layer_names = get_nice_layer_names(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filters = 10\n",
    "conv = keras.layers.Conv2D(n_filters, 1, use_bias=False)\n",
    "conv.build((1, 1, 1, 2*n_filters))\n",
    "kernel = conv.get_weights()[0]\n",
    "print(kernel.shape)\n",
    "conv.set_weights([add_init([int(d) for d in kernel.shape])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = keras.Input(batch_shape=(1, 1, 1, 2*n_filters))\n",
    "y = conv(x)\n",
    "m = keras.Model([x], [y])\n",
    "\n",
    "a = np.random.uniform(size=(1, 1, 1, n_filters))\n",
    "b = np.random.uniform(size=(1, 1, 1, n_filters))\n",
    "out = m.predict(np.concatenate([a, b], -1))\n",
    "np.abs((out - (a + b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import keras.engine.topology\n",
    "import keras.models\n",
    "import keras.layers\n",
    "import keras.layers.convolutional\n",
    "import keras.layers.core\n",
    "import keras.layers.local\n",
    "import keras.layers.noise\n",
    "import keras.layers.normalization\n",
    "import keras.layers.pooling\n",
    "\n",
    "\n",
    "from innvestigate.analyzer import base\n",
    "from innvestigate import layers as ilayers\n",
    "from innvestigate import utils as iutils\n",
    "import innvestigate.utils.keras as kutils\n",
    "from innvestigate.utils.keras import checks as kchecks\n",
    "from innvestigate.utils.keras import graph as kgraph\n",
    "from innvestigate.analyzer.relevance_based import relevance_rule as rrule\n",
    "from innvestigate.analyzer.relevance_based import utils as rutils\n",
    "import innvestigate.analyzer.relevance_based.relevance_analyzer\n",
    "\n",
    "\n",
    "def add_init(shape, dtype=None):\n",
    "    # print(shape)\n",
    "    h, w, cin, cout = shape\n",
    "    weight = np.zeros((cin, cout))\n",
    "    n_inputs = cin // cout\n",
    "    \n",
    "    weight = np.concatenate([np.eye(cout) for _ in range(n_inputs)])\n",
    "    #print(weight)\n",
    "    #plt.imshow(weight)\n",
    "    #plt.show()\n",
    "    return weight[None, None]\n",
    "\n",
    "\n",
    "def get_add_reverse_layer_cls_with_rule(rule):\n",
    "    class AddReverseLayerWithRule(kgraph.ReverseMappingBase):\n",
    "        \"\"\"Special Add layer handler that applies the Z-Rule\"\"\"\n",
    "\n",
    "        def __init__(self, layer, state):\n",
    "            #print(\"in AddReverseLayer.init:\", layer.__class__.__name__,\"-> Dedicated ReverseLayer class\" ) #debug\n",
    "            self._layer_wo_act = kgraph.copy_layer_wo_activation(layer,\n",
    "                                                                 name_template=\"reversed_kernel_%s\")\n",
    "\n",
    "            input_channels = [int(i.shape[-1]) for i in layer.input]\n",
    "            self._merge_layer = keras.layers.Concatenate()\n",
    "\n",
    "\n",
    "            self._sum_layer_with_kernel = keras.layers.Conv2D(input_channels[0], (1, 1), \n",
    "                                                              #kernel_initializer=add_init, \n",
    "                                                              use_bias=False)\n",
    "            self._sum_layer_with_kernel.build((None, None, None, sum(input_channels)))\n",
    "            #self._sum_layer_with_kernel.weights[0].initializer.run(session=K.get_session())\n",
    "                    \n",
    "            weight_shape = [int(d) for d in self._sum_layer_with_kernel.weights[0].shape]\n",
    "            self._sum_layer_with_kernel.set_weights([add_init(weight_shape)])\n",
    "\n",
    "            x = self._merge_layer(layer.input)\n",
    "            x = self._sum_layer_with_kernel(x)\n",
    "\n",
    "            self._rule = rule(self._sum_layer_with_kernel, state)\n",
    "\n",
    "        def apply(self, Xs, Ys, Rs, reverse_state):\n",
    "            def slice_channels(start, end):\n",
    "                def wrapper(x):\n",
    "                    x_slice = x[:, :, :, start:end]\n",
    "                    return K.clip(x_slice, 0, 1000)\n",
    "                return wrapper\n",
    "            merge_Xs = [self._merge_layer(Xs)]\n",
    "            \n",
    "            R_conv = self._rule.apply(merge_Xs, Ys, Rs, reverse_state)[0]\n",
    "            # unmerge\n",
    "            R_returns = []\n",
    "            b, h, w, c = R_conv.shape\n",
    "            cin = c // len(Xs)\n",
    "            for i in range(len(Xs)):\n",
    "                R_returns.append(keras.layers.Lambda(slice_channels(i*cin, (i+1)*cin))(R_conv))\n",
    "            \n",
    "            return [ilayers.Abs()(r) for r in R_returns]\n",
    "        \n",
    "    return AddReverseLayerWithRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bn_reverse_layer_cls_with_rule(rule):\n",
    "    class BatchNormalizationReverseWithRuleLayer(kgraph.ReverseMappingBase):\n",
    "        \"\"\"Special BN handler that applies the Z-Rule\"\"\"\n",
    "\n",
    "        def __init__(self, layer, state):\n",
    "            ##print(\"in BatchNormalizationReverseLayer.init:\", layer.__class__.__name__,\"-> Dedicated ReverseLayer class\" ) #debug\n",
    "            config = layer.get_config()\n",
    "\n",
    "            self._center = config['center']\n",
    "            self._scale = config['scale']\n",
    "            self._axis = config['axis']\n",
    "\n",
    "            self._mean = layer.moving_mean\n",
    "            self._var = layer.moving_variance\n",
    "            if self._center:\n",
    "                self._beta = layer.beta\n",
    "            else:\n",
    "                self._beta = K.zeros_like(self._mean)\n",
    "            if self._scale:\n",
    "                self._gamma = layer.gamma\n",
    "            else:\n",
    "                self._gamma = K.ones_like(self._mean)\n",
    "\n",
    "\n",
    "            channels = int(self._beta.shape[0])\n",
    "            self._bn_as_conv_layer = keras.layers.DepthwiseConv2D((1, 1), use_bias=True)\n",
    "            self._bn_as_conv_layer.build((None, None, None, channels))\n",
    "            self._bn_as_conv_layer.weights[0].initializer.run(session=K.get_session())\n",
    "            self._bn_as_conv_layer.weights[1].initializer.run(session=K.get_session())\n",
    "        \n",
    "            # `output = (x - mean) / sqrt(var + epsilon) * gamma + beta`\n",
    "            #         = x / var_eps * gamma  - gamma * mean / var_eps + beta\n",
    "            # \n",
    "            var_eps = tf.sqrt(self._var + config['epsilon'])\n",
    "            bias = - self._gamma * self._mean / var_eps + self._beta\n",
    "            kernel = self._gamma / var_eps \n",
    "\n",
    "            self._bn_as_conv_layer.depthwise_kernel = tf.identity(kernel[None, None, :, None], name='bn_as_conv_layer_kernel')\n",
    "            self._bn_as_conv_layer.bias = tf.identity(bias, name='bn_as_conv_layer_bias') \n",
    "            self._bn_as_conv_layer._trainable_weights = []\n",
    "            self._bn_as_conv_layer._non_trainable_weights = [self._bn_as_conv_layer.depthwise_kernel, self._bn_as_conv_layer.bias]\n",
    "\n",
    "            x = self._bn_as_conv_layer(layer.input)\n",
    "\n",
    "            self.rule = rule(self._bn_as_conv_layer, state)\n",
    "\n",
    "        def apply(self, Xs, Ys, Rs, reverse_state):\n",
    "            ##print(\"    in BatchNormalizationReverseLayer.apply:\", reverse_state['layer'].__class__.__name__, '(nid: {})'.format(reverse_state['nid']))\n",
    "            rs = self.rule.apply(Xs, Ys, Rs, reverse_state)\n",
    "            if False:\n",
    "                w, b = self._bn_as_conv_layer.get_weights()\n",
    "                plt.title(w.shape)\n",
    "                plt.imshow(w[0, 0])\n",
    "                plt.show()\n",
    "            return rs\n",
    "    \n",
    "    return BatchNormalizationReverseWithRuleLayer\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def custom_add_bn_rule(rule):\n",
    "    try:\n",
    "        old_add_cls = copy.deepcopy(innvestigate.analyzer.relevance_based.relevance_analyzer.AddReverseLayer)\n",
    "        old_bn_cls = copy.deepcopy(innvestigate.analyzer.relevance_based.relevance_analyzer.BatchNormalizationReverseLayer)\n",
    "        if rule is not None:\n",
    "            add_cls = get_add_reverse_layer_cls_with_rule(rule)\n",
    "            bn_cls = get_bn_reverse_layer_cls_with_rule(rule)\n",
    "            print('monkey patching add reverse class with rule', rule)\n",
    "            print('monkey patching bn reverse class with rule', rule)\n",
    "            innvestigate.analyzer.relevance_based.relevance_analyzer.AddReverseLayer = add_cls\n",
    "            innvestigate.analyzer.relevance_based.relevance_analyzer.BatchNormalizationReverseLayer = bn_cls\n",
    "        yield\n",
    "    finally:\n",
    "        innvestigate.analyzer.relevance_based.relevance_analyzer.AddReverseLayer = old_add_cls\n",
    "        innvestigate.analyzer.relevance_based.relevance_analyzer.BatchNormalizationReverseLayer = old_bn_cls\n",
    "    \n",
    "\n",
    "shp = (1, 1, 1, 8)\n",
    "x = keras.Input(batch_shape=shp)\n",
    "rel_bp = keras.Input(batch_shape=shp)\n",
    "bn = keras.layers.BatchNormalization()\n",
    "o = bn(x)\n",
    "\n",
    "bn_rev_cls = get_bn_reverse_layer_cls_with_rule(rrule.Alpha1Beta0Rule)\n",
    "bn_rev = bn_rev_cls(bn, None)\n",
    "rel = bn_rev.apply([x], [o], [rel_bp], {})\n",
    "\n",
    "rel_np, out_np = K.get_session().run([rel, o], feed_dict={\n",
    "    x: np.ones(shp),  rel_bp: np.ones(shp)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_np, out_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bn = model.layers[172]\n",
    "bn_rev = get_bn_reverse_layer_cls_with_rule(rrule.Alpha1Beta0Rule)(bn, {})\n",
    "\n",
    "x = keras.Input(batch_shape=bn.input_shape)\n",
    "conv_out = bn_rev._bn_as_conv_layer(x)\n",
    "bn_out = bn(x, training=False)\n",
    "\n",
    "conv_out_np, bn_out_np = K.get_session().run([conv_out, bn_out], \n",
    "                                       feed_dict={x: np.ones((1, ) + bn.input_shape[1:])})\n",
    "np.abs(conv_out_np - bn_out_np).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(conv_out_np.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(bn_out_np.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((conv_out_np - bn_out_np)[0, 0, :, :100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "channels = 5\n",
    "\n",
    "for rule in [None, rrule.ZRule, rrule.Alpha1Beta0Rule]: #, rrule.Alpha2Beta1Rule, None]:\n",
    "    sess = K.get_session()\n",
    "    with custom_add_bn_rule(rule):\n",
    "        shp = (1, 1, 1, channels)\n",
    "        a = keras.Input(batch_shape=shp)\n",
    "        b = keras.Input(batch_shape=shp)\n",
    "        add = keras.layers.Add()\n",
    "        add.build([shp, shp])\n",
    "        o = add([a, b])\n",
    "        \n",
    "        \n",
    "        add_reverse = innvestigate.analyzer.relevance_based.relevance_analyzer.AddReverseLayer(add, None)\n",
    "        rel = K.placeholder(shape=(1, 1, 1, channels))\n",
    "\n",
    "        relevances = add_reverse.apply([a, b], [o], [rel], None)\n",
    "         \n",
    "        print(rule, add_reverse)\n",
    "        for sa, sb, sr in [(2, 1, 1), (-2, 1, 1), (-2, -1, 1), (2, -1, 1)]:\n",
    "            print(\"scales\", sa, sb, sr)\n",
    "            rel_a, rel_b, output = sess.run(relevances + [o], feed_dict={a: sa*np.ones((1, 1, 1, channels)), \n",
    "                                                            b: sb*np.ones((1, 1, 1, channels)),\n",
    "                                                            rel: sr*np.ones((1, 1, 1, channels))\n",
    "                                                           })\n",
    "            print('rel_a', rel_a.flatten())\n",
    "            print('rel_b', rel_b.flatten())\n",
    "            print('output', output.flatten())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_rule in ['lrp.z', 'lrp.alpha_1_beta_0', 'lrp.alpha_2_beta_1']:\n",
    "    keras.backend.clear_session()\n",
    "    model, innv_net, color_conversion = load_model('resnet50', load_weights)\n",
    "    ex_image, ex_target, val_images, selected_img_idxs = load_val_images(\n",
    "        innv_net, imagenet_val_dir, ex_image_path, n_selected_imgs)\n",
    "    add_rules = [None , rrule.Alpha1Beta0Rule, rrule.Alpha2Beta1Rule]\n",
    "    hmaps = []\n",
    "    analyzers = []\n",
    "    for add_rule in add_rules: \n",
    "        with custom_add_bn_rule(add_rule):\n",
    "            analyzer = innvestigate.analyzer.create_analyzer(model_rule, model, \n",
    "                                                             #reverse_check_min_max_values=True, \n",
    "                                                             #reverse_clip_values=(0, 100),\n",
    "                                                             reverse_keep_tensors=True)\n",
    "            hmap = analyzer.analyze(ex_image)\n",
    "            \n",
    "            if add_rule is None:\n",
    "                add_rule_name = \"original add\"\n",
    "            else:\n",
    "                add_rule_name = add_rule.__name__\n",
    "                \n",
    "            analyzers.append((add_rule_name, analyzer))\n",
    "            hmaps.append((add_rule_name, hmap))\n",
    "            \n",
    "            plt.title(\"{} with add rule: {}\".format(model_rule, add_rule_name))\n",
    "            plt.imshow(hmap[0].sum(-1))\n",
    "            plt.colorbar()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, tensor in analyzer._reversed_tensors:\n",
    "    if idx == (172, 1):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.min(), tensor.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tensor.flatten(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = rrule.Alpha1Beta0Rule\n",
    "old_add_cls = copy.deepcopy(innvestigate.analyzer.relevance_based.relevance_analyzer.AddReverseLayer)\n",
    "add_cls = get_add_reverse_layer_cls_with_rule(rule)\n",
    "innvestigate.analyzer.relevance_based.relevance_analyzer.AddReverseLayer = add_cls\n",
    "print(innvestigate.analyzer.relevance_based.relevance_analyzer.AddReverseLayer)\n",
    "rule = analyzer._reverse_mapping(model.layers[173])\n",
    "print(rule)\n",
    "print(dir(rule))\n",
    "print(rule.rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule.apply([], [], [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice_layer_names['resnet50'][172]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[174]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.layers[173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmap.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmap.max() / np.abs(hmap.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = m.predict(np.concatenate([a, b], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = {'vgg16': 22, 'resnet50': 177}\n",
    "\n",
    "replacement_layers = {\n",
    "    'vgg16':  ['fc3', 'fc1', 'conv4_3', 'conv3_3', 'conv2_2'],\n",
    "    'resnet50': ['dense', 'block5_1', 'block4_2', 'block3_4', 'block3_2', 'block2_2'],\n",
    "}\n",
    "\n",
    "output_shapes = get_output_shapes(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmap_postprocess_wrapper(name):\n",
    "    return lambda x: heatmap_postprocess(name, x)\n",
    "\n",
    "input_range = (ex_image.min(), ex_image.max())\n",
    "analysers = get_analyser_params(input_range)\n",
    "\n",
    "attr_names = [n for (n, _, _, _, _) in analysers]\n",
    "    \n",
    "hmap_postprocessing = {\n",
    "    n: hmap_postprocess_wrapper(post_name) for n, _, post_name, _, _ in analysers\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 0.9, 10).tolist() + [0.99, 0.999, 0.9999, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_reversed(hidden):\n",
    "    return [h[1] for h in hidden[1:]]\n",
    "\n",
    "\n",
    "dead_neuron_mask = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    keras.backend.clear_session()\n",
    "    model, innv_net, _ = load_model(model_name, load_weights=True)\n",
    "    analyser = innvestigate.create_analyzer(\n",
    "        \"gradient\", model, reverse_keep_tensors=True)\n",
    "    \n",
    "    analyser.analyze(np.concatenate([img for (img, _) in val_images[:20]], 0))\n",
    "    \n",
    "    grad_hidden = parse_reversed(analyser._reversed_tensors) \n",
    "    dead_neuron_mask[model_name] = [(0 == np.mean(g, 0, keepdims=True)).all(-1, keepdims=True) for g in grad_hidden]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    plt.title(model_name + \" - active neurons\")\n",
    "    plt.plot([(m.sum(-1) / m.shape[-1] > 0.999999).mean() for m in dead_neuron_mask[model_name]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice_layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram_layers = copy.deepcopy(replacement_layers)\n",
    "histogram_layers['vgg16'].extend(['conv1_1', 'input'])\n",
    "histogram_layers['resnet50'].extend(['conv2_1a', 'input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "histogram_layers_idx = OrderedDict()\n",
    "for model_name in model_names:\n",
    "    histogram_layers_idx[model_name] = []\n",
    "    for layer_name in histogram_layers[model_name]:\n",
    "        idx = get_layer_idx_full(model_name, nice_layer_names, layer_name)\n",
    "        histogram_layers_idx[model_name].append(idx) \n",
    "histogram_layers_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dead_neuron_mask['vgg16'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_layers= {'vgg16': ['fc3'], 'resnet50': ['dense']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacement_layer_indices = [22]\n",
    "n_sampled_v = 5\n",
    "\n",
    "cos_sim_histograms = {}\n",
    "cos_mean = {}\n",
    "selected_percentiles = [0, 1, 5, 10, 20, 50, 100]\n",
    "cos_sim_percentiles = {}\n",
    "\n",
    "for label, innv_name, _, excludes, kwargs in tqdm.tqdm_notebook(analysers):\n",
    "    if 'exclude_cos_sim' in excludes:\n",
    "        continue\n",
    "    for model_name in model_names[:1]:\n",
    "        if 'exclude_' + model_name in excludes:\n",
    "            continue\n",
    "        keras.backend.clear_session()\n",
    "        model_wo_softmax, innv_net, _ = load_model(model_name, load_weights=load_weights)\n",
    "        if innv_name == \"pattern.attribution\":\n",
    "            kwargs['patterns'] = innv_net['patterns']\n",
    "\n",
    "        for replacement_layer in replacement_layers[model_name]:\n",
    "            replacement_layer_idx = get_layer_idx_full(model_name, nice_layer_names, replacement_layer)\n",
    "            repl_analyser, repl_shape = get_replacement_analyser(\n",
    "                model_wo_softmax, innv_name,  \n",
    "                replacement_layer_idx=replacement_layer_idx,\n",
    "                **kwargs)\n",
    "            repl_analyser.create_analyzer_model()\n",
    "            cos_per_img = OrderedDict()\n",
    "            for img_idx, (img, _) in tqdm.tqdm_notebook(zip(selected_img_idxs, val_images), \n",
    "                desc=\"[{}.{}] {}\".format(model_name, replacement_layer, label)):\n",
    "                channels = repl_shape[-1]\n",
    "                if label == \"$\\\\alpha=100, \\\\beta=99$-LRP\":\n",
    "                    # a=100,b=99 sufferes numerical instabilities with std = 1\n",
    "                    std = 1 / np.sqrt(channels)\n",
    "                else:\n",
    "                    std = 1\n",
    "\n",
    "                relevance_v1 = std*np.random.normal(size=(1, ) + repl_shape[1:]) \n",
    "                hmap = repl_analyser.analyze([img, relevance_v1])\n",
    "                intermediate_values = parse_reversed(repl_analyser._reversed_tensors)\n",
    "\n",
    "                relevance_v2 = std * np.random.normal(size=(n_sampled_v,) + repl_shape[1:]) \n",
    "                img_tiled = np.tile(img, (n_sampled_v, 1, 1, 1))\n",
    "                outs = repl_analyser.get_cosine(img_tiled, relevance_v2,  intermediate_values[::-1])\n",
    "                outs = outs[::-1]\n",
    "                for layer_idx, (o, dead_neuron) in enumerate(zip(outs, dead_neuron_mask[model_name])):\n",
    "                    cos_for_layer = np.abs(o)\n",
    "                    # we filter 0 cosine similarites as they only appear practically when the gradients are zero\n",
    "                    cos_per_img[model_name, layer_idx, img_idx] = cos_for_layer[cos_for_layer != 0]\n",
    "            \n",
    "            median_for_label = []\n",
    "            percentile_for_label = OrderedDict([(p, []) for p in selected_percentiles])\n",
    "            for layer_idx in range(n_layers[model_name]):\n",
    "                cos_per_layer = np.concatenate([cos_per_img[model_name, layer_idx, img_idx]  for img_idx in selected_img_idxs])\n",
    "                cos_per_layer = cos_per_layer.flatten()\n",
    "                \n",
    "                idx = (label, model_name, replacement_layer_idx,  layer_idx)\n",
    "                cos_mean[idx] = np.mean(cos_per_layer)\n",
    "                \n",
    "                perc_values = np.percentile(cos_per_layer,  selected_percentiles)\n",
    "                for p, val in zip(selected_percentiles, perc_values):\n",
    "                    percentile_for_label[p].append(val)\n",
    "                    \n",
    "                if layer_idx in histogram_layers_idx[model_name]:\n",
    "                    \n",
    "                    if len(cos_per_layer) > 50000:\n",
    "                        ridx = np.random.choice(len(cos_per_layer), 50000, replace=False)\n",
    "                        cos_per_layer_sel = cos_per_layer[ridx]\n",
    "                    else:\n",
    "                        cos_per_layer_sel = cos_per_layer\n",
    "                        \n",
    "                    cos_sim_histograms[idx] = np.histogram(cos_per_layer_sel, bins)\n",
    "\n",
    "\n",
    "            for p, values in percentile_for_label.items():\n",
    "                cos_sim_percentiles[label, model_name, replacement_layer_idx, p] = np.array(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with keras.backend.get_session().as_default():\n",
    "    print(1 - tf.losses.cosine_distance([0, 0], [0, 0], 0).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs[0].shape, outs[-4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = False\n",
    "if save_results:\n",
    "    os.makedirs('cache', exist_ok=True)\n",
    "    with open('cache/cos_sim_with_hist_random_weights.pickle', 'wb') as f:\n",
    "        pickle.dump((cos_sim_percentiles, cos_sim_histograms ), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_results = False\n",
    "if load_results:\n",
    "    os.makedirs('cache', exist_ok=True)\n",
    "    with open('cache/cos_sim_with_hist.pickle', 'rb') as f:\n",
    "        cos_sim_percentiles, cos_sim_histograms = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(U, V):\n",
    "    v_norm = V / np.linalg.norm(V, axis=0, keepdims=True)\n",
    "    u_norm = U / np.linalg.norm(U, axis=0, keepdims=True)\n",
    "    return v_norm.T @ u_norm\n",
    "\n",
    "def get_sample_cos_sim_per_layer(output_shapes):\n",
    "    values = []\n",
    "    for layer_idx, shp in output_shapes.items():\n",
    "        ch = shp[-1]\n",
    "        n_samples = 1000\n",
    "        u = np.random.normal(size=(ch, n_samples))\n",
    "        v = np.random.normal(size=(ch, n_samples))\n",
    "        cos = cosine_similarity(v, u)\n",
    "        mask = np.tri(cos.shape[0])\n",
    "        values.append(np.median(np.abs(cos[mask == 1])))\n",
    "    return np.array(values)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_baseline = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    keras.backend.clear_session()\n",
    "    model, _, _ = load_model(model_name)\n",
    "    output_shapes = get_output_shapes(model)\n",
    "    print(len(output_shapes))\n",
    "    cos_sim_baseline[model_name] = get_sample_cos_sim_per_layer(output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_baseline['vgg16'].shape, cos_sim_baseline['resnet50'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = OrderedDict()\n",
    "\n",
    "os.makedirs('figures/cosine_similarity', exist_ok=True)\n",
    "for model_name in model_names[::-1]:\n",
    "    for replacement_layer in replacement_layers[model_name]:\n",
    "        repl_idx = get_layer_idx_full(model_name, nice_layer_names, replacement_layer)\n",
    "        start_layer = n_layers[model_name] - repl_idx \n",
    "        \n",
    "        layer_names = [name for idx, name in nice_layer_names[model_name].items()\n",
    "                       if idx <= repl_idx][::-1]\n",
    "        layer_idx = np.array([idx for idx, name in nice_layer_names[model_name].items()\n",
    "                       if idx < repl_idx][::-1])\n",
    "        \n",
    "        print(layer_idx, repl_idx, start_layer)\n",
    "        #layer_idx = layer_idxs\n",
    "        \n",
    "        plt.figure(figsize=(max(3, len(layer_idx) / 4), 3.5))\n",
    "        \n",
    "        for i, (label, _, _, _, _) in enumerate(analysers):\n",
    "            idx = (label, model_name, repl_idx, 50)\n",
    "            if idx not in cos_sim_percentiles:\n",
    "                warnings.warn(\"not found: \" + str(idx))\n",
    "                continue\n",
    "            print(len(cos_sim_percentiles[idx]))\n",
    "            cos_sim_per_label = cos_sim_percentiles[idx][layer_idx]\n",
    "            \n",
    "            #cos_sim_per_label = []\n",
    "            #for lidx in layer_idx:\n",
    "            #    cos_sim_per_label.append(cos_mean[label, model_name, repl_idx, lidx])\n",
    "            # try:\n",
    "            #     cos_sim_per_label = cos_sim_percentiles[idx][layer_idx]\n",
    "            # except IndexError:\n",
    "            #     cos_sim_per_label = (cos_sim_baseline[model_name][layer_idx[:1]].tolist() +\n",
    "            #                          cos_sim_percentiles[idx][layer_idx[1:]].tolist())\n",
    "                \n",
    "            plt.plot(0.5 + np.arange(len(cos_sim_per_label)), cos_sim_per_label, label=label, **mpl_styles[label])\n",
    "            \n",
    "            if label not in legend:\n",
    "                legend[label] = mpl_styles[label]\n",
    "            \n",
    "        # Random Cos Similarity\n",
    "        # Cos Similarity Base.\n",
    "        label='Cos Similarity BL'\n",
    "        style = {'color': (0.25, 0.25, 0.25)}\n",
    "        plt.plot(0.5 + np.arange(len(layer_idx)), cos_sim_baseline[model_name][layer_idx], \n",
    "                 # label='Cos. Sim. Baseline', \n",
    "                 label=label,\n",
    "                 **style)\n",
    "        if label not in legend:\n",
    "            legend[label] = style\n",
    "        \n",
    "        #plt.legend(bbox_to_anchor=(1, 1))\n",
    "        plt.ylabel('cosine similarity')\n",
    "        plt.xticks(np.arange(len(layer_names)), layer_names, rotation=90)\n",
    "        plt.ylim(-0.05, 1.05)\n",
    "        plt.grid('on', alpha=0.35) #, axis=\"y\")\n",
    "        plt.savefig(\"./figures/cosine_similarity/{}_layer_{}.pdf\".format(model_name, repl_idx),  \n",
    "                    bbox_inches='tight', pad_inches=0)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(cos_mean.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.5, 3))\n",
    "for label, style in legend.items():\n",
    "    plt.plot([], label=label, alpha=1, **style)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.legend(loc='center')\n",
    "plt.savefig(\"./figures/cos_sim_legend.pdf\",\n",
    "            bbox_inches='tight', pad_inches=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(IFrame(\"./figures/cos_sim_legend.pdf\", 800, 600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr_name, model_name, layer_idx, percentile in cos_sim_percentiles.keys():\n",
    "    if attr_name == 'GuidedBP' and model_name == 'resnet50':\n",
    "        print(attr_name, model_name, layer_idx, percentile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_percentiles.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
