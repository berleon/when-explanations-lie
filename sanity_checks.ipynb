{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When Explanations Lie: Why Modified BP Attribution fails\n",
    "\n",
    "This notebook produces the heatmap figures and the ssim results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to install install packages\n",
    "#!pip install tensorflow-gpu==1.13.1\n",
    "#!pip install innvestigate seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "import innvestigate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import PIL \n",
    "import copy\n",
    "import contextlib\n",
    "\n",
    "import imp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from skimage.measure import compare_ssim \n",
    "import pickle\n",
    "import datetime\n",
    "from collections import OrderedDict\n",
    "from IPython.display import IFrame, display\n",
    "\n",
    "import keras\n",
    "import keras.backend\n",
    "import keras.models\n",
    "\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.applications.imagenet\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "from innvestigate.analyzer.relevance_based.relevance_analyzer import LRP\n",
    "from innvestigate.analyzer.base import AnalyzerNetworkBase, ReverseAnalyzerBase\n",
    "from innvestigate.analyzer.deeptaylor import DeepTaylor\n",
    "\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "from when_explanations_lie import *\n",
    "from monkey_patch import custom_add_bn_rule, get_custom_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def _prepare_model(self, model):\n",
    "#    return super(DeepTaylor, self)._prepare_model(model)\n",
    "#\n",
    "## otherwise DTD does not work on negative outputs\n",
    "#DeepTaylor._prepare_model = _prepare_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to imagenet validation\n",
    "# imagenet_val_dir = \"/home/leonsixt/tmp/imagenet/imagenet-raw/validation\"\n",
    "imagenet_val_dir = \"/mnt/ssd/data/imagenet/imagenet-raw/validation\"\n",
    "# path to examplary image\n",
    "ex_image_path = \"n01534433/ILSVRC2012_val_00015410.JPEG\"\n",
    "# number of images to run the evaluation\n",
    "n_selected_imgs = 10\n",
    "\n",
    "model_names = ['resnet50', 'vgg16']\n",
    "\n",
    "assert os.path.exists(imagenet_val_dir)\n",
    "os.makedirs('figures', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, innv_net, color_conversion = load_model('vgg16')\n",
    "ex_image_vgg, ex_target, val_images, selected_img_idxs = load_val_images(\n",
    "    innv_net, imagenet_val_dir, ex_image_path, n_selected_imgs)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "model, innv_net, color_conversion = load_model('resnet50')\n",
    "ex_image, ex_target, val_images, selected_img_idxs = load_val_images(\n",
    "    innv_net, imagenet_val_dir, ex_image_path, n_selected_imgs)\n",
    "\n",
    "\n",
    "assert ((ex_image - ex_image_vgg) == 0).all()\n",
    "print(\"Loaded {} images\".format(n_selected_imgs))\n",
    "\n",
    "nice_layer_names = get_nice_layer_names(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = {'vgg16': 22, 'resnet50': 177}\n",
    "\n",
    "randomization_layers = {\n",
    "    'vgg16': [\"conv1_1\", \"conv2_1\",  \"conv3_1\", \"conv4_1\",  \"conv4_3\",  \"conv5_1\", \"conv5_3\", \"fc1\", \"fc3\"],\n",
    "    'resnet50': ['conv1', 'block2_2', 'block3_1', 'block3_3', 'block4_1', 'block4_6', 'block5_2', 'dense'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_shapes = get_output_shapes(model)\n",
    "\n",
    "print_output_shapes = False \n",
    "if print_output_shapes: \n",
    "    print(\"{:3}{:20}{:20}{}\".format(\"l\", \"layer\", \"input_at_0\", \"output_shape\"))\n",
    "    for i in range(len(model.layers)):\n",
    "        layer = model.get_layer(index=i)\n",
    "        print(\"{:3}: {:20}  {:20}  {}\".format(\n",
    "            i, layer.name, str(layer.get_input_shape_at(0)), str(output_shapes[i])))\n",
    "        #print(\"{:3}: {:20}  {:20}  {}\".format(i, type(layer).__name__, layer.name, output_shapes[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmap_postprocess_wrapper(name):\n",
    "    return lambda x: heatmap_postprocess(name, x)\n",
    "\n",
    "input_range = (ex_image.min(), ex_image.max())\n",
    "analysers = get_analyser_params(input_range)\n",
    "\n",
    "attr_names = [n for (n, _, _, _, _) in analysers]\n",
    "    \n",
    "hmap_postprocessing = {\n",
    "    n: hmap_postprocess_wrapper(post_name) for n, _, post_name, _, _ in analysers\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, name in enumerate(attr_names):\n",
    "    style = mpl_styles[name]\n",
    "    plt.plot(np.arange(10), [20-i] * 10, \n",
    "             #markersize=5,\n",
    "             label=name + \" m=\" + style['marker'], **style)\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks: Random Parameters & Logit Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cascading, _, _ = load_model('resnet50')\n",
    "model_random, _, _ = load_model('resnet50', load_weights=False)\n",
    "model_cascading.set_weights(model.get_weights())\n",
    "out = model.predict(ex_image)\n",
    "out_cascading = model_cascading.predict(ex_image)\n",
    "print(\"mean-l1 distance of the outputs of the trained model and when weights are from trained model [should be 0]:\", np.abs(out_cascading - out).mean())\n",
    "\n",
    "n_layers = len(model_random.layers)\n",
    "copy_weights(model_cascading, model_random, range(n_layers - 3, n_layers))\n",
    "\n",
    "out = model.predict(ex_image)\n",
    "out_cascading = model_cascading.predict(ex_image)\n",
    "print( \"mean-l1 distance of the outputs of the trained model when the last 2 layers are random [should not be 0]:\", np.abs(out_cascading - out).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'hmap_output_dir' in globals():\n",
    "    raise Exception()\n",
    "hmap_output_dir = 'cache/' + datetime.datetime.now().isoformat()\n",
    "os.makedirs(hmap_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hmap_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmaps are saved in those dicts\n",
    "\n",
    "recreate_analyser = False\n",
    "for model_name in tqdm.tqdm_notebook(model_names):\n",
    "    get_layer_idx = lambda layer_name: get_layer_idx_full(\n",
    "        model_name, nice_layer_names, layer_name)\n",
    "    \n",
    "    for i, (attr_name, innv_name, _, excludes, analyser_kwargs) in enumerate(tqdm.tqdm_notebook(\n",
    "        analysers, desc=model_name)):\n",
    "        \n",
    "        hmap_original = OrderedDict()\n",
    "        hmap_random_weights = OrderedDict()\n",
    "        hmap_random_target = OrderedDict()\n",
    "        \n",
    "        if i % 1 == 0:\n",
    "            # clear session from time to time to not OOM\n",
    "            keras.backend.clear_session()\n",
    "\n",
    "            model, innv_net, _ = load_model(model_name)\n",
    "            model_cascading, _, _ = load_model(model_name)\n",
    "            model_random, _, _ = load_model(model_name, load_weights=False)\n",
    "            model_cascading.set_weights(model.get_weights())\n",
    "            \n",
    "        if \"exclude_\" + model_name in excludes:\n",
    "            continue\n",
    "        if innv_name == 'pattern.attribution':\n",
    "            analyser_kwargs['patterns'] = innv_net['patterns']\n",
    "\n",
    "        cascading_heatmaps = {}\n",
    "        cascading_outputs = {}\n",
    "        model_cascading.set_weights(model.get_weights())\n",
    "\n",
    "        original_idx = len(model.layers)\n",
    "        custom_rule = get_custom_rule(innv_name, analyser_kwargs)\n",
    "        with custom_add_bn_rule(custom_rule):\n",
    "            analyzer_cascading = innvestigate.create_analyzer(\n",
    "                innv_name, model_cascading, \n",
    "                neuron_selection_mode=\"index\", **analyser_kwargs)\n",
    "\n",
    "            for img_idx, (img_pp, target) in zip(selected_img_idxs, val_images):\n",
    "                random_target = get_random_target(target)\n",
    "                hmap_random_target[model_name, attr_name, img_idx] = (\n",
    "                    random_target, analyzer_cascading.analyze(img_pp, neuron_selection=random_target)[0])\n",
    "            selected_layers = [('original', original_idx)] +  [\n",
    "                (name, get_layer_idx(name)) \n",
    "                 for name in randomization_layers[model_name][::-1]\n",
    "            ]\n",
    "            for layer_name, layer_idx in tqdm.tqdm_notebook(selected_layers, desc=attr_name):\n",
    "                copy_weights(model_cascading, model_random, range(layer_idx, original_idx))\n",
    "                if recreate_analyser:\n",
    "                    analyzer_cascading = create_analyzer(\n",
    "                        analyser, model_cascading, \n",
    "                        neuron_selection_mode=\"index\",  **analyser_kwargs)\n",
    "\n",
    "                for img_idx, (img_pp, target) in zip(selected_img_idxs, val_images):\n",
    "                    hmap = analyzer_cascading.analyze(img_pp, neuron_selection=target)[0]\n",
    "                    if layer_idx == original_idx:\n",
    "                        hmap_original[model_name, attr_name, img_idx] = hmap\n",
    "                    else:\n",
    "                        hmap_random_weights[model_name, attr_name, img_idx, layer_idx] =  hmap\n",
    "\n",
    "\n",
    "            with open(hmap_output_dir + '/heatmap_{}_{}.pickle'.format(model_name, attr_name), 'wb') as f:\n",
    "                pickle.dump((hmap_original, hmap_random_weights, hmap_random_target), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_heatmaps = False\n",
    "\n",
    "if dump_heatmaps:\n",
    "    os.makedirs('cache', exist_ok=True)\n",
    "    with open('cache/heatmaps_v4.pickle', 'wb') as f:\n",
    "        pickle.dump((hmap_original, hmap_random_weights, hmap_random_target, analysers), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print size of dump\n",
    "! ls -lh 'heatmaps.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_heatmaps = False\n",
    "if load_heatmaps:\n",
    "    with open('heatmaps.pickle', 'rb') as f:\n",
    "        hmap_original, hmap_random_weights, hmap_random_target, analysers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attr_names = sorted(set([n for (n, _) in hmap_original.keys()]))\n",
    "attr_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_random_weights = OrderedDict()\n",
    "l2_random_weights = OrderedDict()\n",
    "\n",
    "last_idx = len(model.layers)\n",
    "for model_name in model_names:\n",
    "    for attr_name in attr_names:\n",
    "        outpath = hmap_output_dir + '/heatmap_{}_{}.pickle'.format(model_name, attr_name)\n",
    "        if not os.path.exists(outpath):\n",
    "            warnings.warn(\"not found: \" + outpath)\n",
    "            continue\n",
    "        with open(outpath, 'rb') as f:\n",
    "            hmap_original, hmap_random_weights, hmap_random_target = pickle.load(f)\n",
    "        \n",
    "        for (model_name, name, img_idx, layer_idx), heatmap in tqdm.tqdm_notebook(\n",
    "            hmap_random_weights.items(), desc=\"{}.{}\".format(model_name, attr_name)):\n",
    "            original_heatmap = hmap_original[model_name, name, img_idx]\n",
    "            postprocess = hmap_postprocessing[name]\n",
    "            original_heatmap = postprocess(original_heatmap)\n",
    "            heatmap = postprocess(heatmap)\n",
    "            ssim_random_weights[model_name, name, img_idx, layer_idx] = ssim_flipped(heatmap, original_heatmap)\n",
    "            l2_random_weights[model_name, name, img_idx, layer_idx] = l2_flipped(heatmap, original_heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_random_target = OrderedDict()\n",
    "\n",
    "for model_name in model_names:\n",
    "    for attr_name in attr_names:\n",
    "        outpath = hmap_output_dir + 'cache/heatmap_{}_{}.pickle'.format(model_name, attr_name)\n",
    "        if not os.path.exists(outpath):\n",
    "            warnings.warn(\"not found: \" + outpath)\n",
    "            continue\n",
    "        with open(outpath, 'rb') as f:\n",
    "            hmap_original, hmap_random_weights, hmap_random_target = pickle.load(f)\n",
    "        for (model_name, attr_name, img_idx), (_, hmap_random) in tqdm.tqdm_notebook(\n",
    "            hmap_random_target.items()):\n",
    "            if (model_name, attr_name) not in ssim_random_target:\n",
    "                ssim_random_target[model_name, attr_name] = []\n",
    "\n",
    "            postprocess = hmap_postprocessing[attr_name]\n",
    "\n",
    "            hmap = hmap_original[model_name, attr_name, img_idx]\n",
    "            original_heatmap = postprocess(original_heatmap)\n",
    "            hmap = postprocess(hmap)\n",
    "            hmap_random = postprocess(hmap_random)\n",
    "            ssim_random_target[model_name, attr_name].append(\n",
    "                ssim_flipped(hmap, hmap_random))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_random_target.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    with sns.axes_style('ticks', {\"axes.grid\": True, 'font.family': 'serif'}):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(4, 3.0), squeeze=True)\n",
    "\n",
    "\n",
    "        xlabels =  [n for (m, n) in ssim_random_target.keys() if m == model_name]\n",
    "        bars = ax.boxplot([ssim_random_target[model_name, n] for n in xlabels]) \n",
    "        ax.set_ylabel('SSIM')\n",
    "        #ax.set_xticks(np.arange(len(xlabels)))\n",
    "        ax.set_xticklabels(xlabels, rotation=90)\n",
    "        ax.set_ylim(-0.05, 1.05)\n",
    "        \n",
    "        os.makedirs('figures', exist_ok=True)\n",
    "        figpath = 'figures/random-logit-boxplot-{}.pdf'.format(model_name)\n",
    "        fig.savefig(figpath,  bbox_inches='tight', pad_inches=0)\n",
    "        display(IFrame(figpath, 800, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ssim_reduce = 'median'\n",
    "confidence_intervals = True\n",
    "confidence_percentile = 99.5\n",
    "\n",
    "for model_name in model_names:\n",
    "    \n",
    "    selected_layers = [\n",
    "        (name, get_layer_idx_full(model_name, nice_layer_names, name)) \n",
    "         for name in randomization_layers[model_name][::-1]\n",
    "    ]\n",
    "    \n",
    "    with sns.axes_style(\"ticks\", {\"axes.grid\": True, 'font.family': 'serif'}):\n",
    "        # metrics = [('SSIM', ssim), ('MSE', l2_random_weights)]\n",
    "        metrics = [('SSIM', ssim_random_weights)]\n",
    "        fig, axes = plt.subplots(1, len(metrics), figsize=(4.5 * len(metrics), 3.5), squeeze=False)\n",
    "        axes = axes[0]\n",
    "        for ax, (ylabel, metric) in zip(axes, metrics): \n",
    "            for (name, _, _, excludes, _) in analysers:\n",
    "                if 'exclude_' + model_name in excludes:\n",
    "                    continue\n",
    "                    \n",
    "                metric_per_layer = []\n",
    "\n",
    "                lower_conf = []\n",
    "                upper_conf = []\n",
    "                for (_, layer_idx) in selected_layers[::-1]:\n",
    "                    metric_per_layer.append(\n",
    "                        [metric[model_name, name, img_idx, layer_idx] for img_idx in selected_img_idxs]\n",
    "                    )\n",
    "                    if confidence_intervals:\n",
    "                        vals = np.array(metric_per_layer[-1])\n",
    "                        ridx = np.random.choice(len(vals), (10000, len(vals)), replace=True)\n",
    "                        resample = vals[ridx]\n",
    "                        stats = np.median(resample, 1)\n",
    "                        lower_conf.append(np.percentile(stats, 100 - confidence_percentile))\n",
    "                        upper_conf.append(np.percentile(stats, confidence_percentile))\n",
    "\n",
    "                metric_per_layer = np.array(metric_per_layer)\n",
    "\n",
    "                if ssim_reduce == 'mean':\n",
    "                    ssims_reduced = metric_per_layer.mean(1)\n",
    "                elif ssim_reduce == 'median':\n",
    "                    ssims_reduced = np.median(metric_per_layer, 1)\n",
    "\n",
    "                ticks = np.arange(len(ssims_reduced))\n",
    "                ax.plot(ticks, ssims_reduced[::-1], label=name, **mpl_styles[name])\n",
    "                ax.fill_between(ticks, lower_conf[::-1], upper_conf[::-1], \n",
    "                                color=mpl_styles[name]['color'],\n",
    "                                alpha=0.25\n",
    "                               )\n",
    "                #ax.plot(ticks, lower_conf, color=linestyles[name]['color'])\n",
    "                #ax.plot(ticks, upper_conf, color=linestyles[name]['color'])\n",
    "\n",
    "            xlabels = [layer_name for layer_name, _ in selected_layers] \n",
    "            ax.set_ylim([0, 1.05])\n",
    "            ax.set_xticks(np.arange(len(xlabels)))\n",
    "            ax.set_xticklabels(xlabels, rotation=90)\n",
    "            ax.set_ylabel(ylabel)\n",
    "        axes[-1].legend(bbox_to_anchor=(1.0, 1.00))\n",
    "        plt.savefig('ssim-random-weights-{}.pdf'.format(model_name),  bbox_inches='tight', pad_inches=0)\n",
    "        plt.show()\n",
    "        display(IFrame('ssim-random-weights-{}.pdf'.format(model_name), 800, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap_grid(heatmaps, cols, row_labels=[], column_labels=[], fig_path=None, figsize=None):\n",
    "    mpl.rcParams['font.family'] = 'serif'\n",
    "    rows = len(heatmaps) // cols\n",
    "    \n",
    "    if figsize is None:\n",
    "        figsize = (cols, rows)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize, squeeze=False)\n",
    "    fontsize = 9\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.05, top=1, bottom=0, left=0, right=1)\n",
    "    for label, ax in zip(row_labels, axes[:, 0]):\n",
    "        ax.set_ylabel(label, fontsize=fontsize + 1, labelpad=55, rotation=0)\n",
    "        \n",
    "    print(axes.shape, column_labels, row_labels)\n",
    "    for label, ax in zip(column_labels, axes[0, :]):\n",
    "        ax.set_title(label, fontsize=fontsize)\n",
    "        \n",
    "        \n",
    "    for ax, heatmap in zip(axes.flatten(), heatmaps):\n",
    "        ax.imshow(heatmap, cmap='seismic', vmin=-1, vmax=1)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    if fig_path is not None:\n",
    "        plt.savefig(fig_path, bbox_inches='tight', pad_inches=0, dpi=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_neg(x):\n",
    "    vmax = np.percentile(x, 99)\n",
    "    vmin = np.percentile(x, 1)\n",
    "    vmax\n",
    "    x_pos = x * (x > 0)\n",
    "    x_neg = x * (x < 0)\n",
    "    \n",
    "    x_pos = x_pos / vmax\n",
    "    x_neg = - x_neg / vmin\n",
    "    return np.clip(x_pos + x_neg, -1, 1)\n",
    "\n",
    "\n",
    "def load_examplary_heatmap():\n",
    "    hmap_loaded = []\n",
    "    for model_name in model_names:\n",
    "        rnd_layers = randomization_layers[model_name][::-1]\n",
    "        for (attr_name, _, _, excludes, _) in tqdm.tqdm_notebook(analysers):\n",
    "            if 'exclude_' + model_name in excludes:\n",
    "                print(attr_name)\n",
    "                continue\n",
    "            try:\n",
    "                outpath = hmap_output_dir + '/heatmap_{}_{}.pickle'.format(model_name, attr_name)\n",
    "                if not os.path.exists(outpath):\n",
    "                    warnings.warn(\"not found: \" + outpath)\n",
    "                    continue\n",
    "                with open(outpath, 'rb') as f:\n",
    "                    hmap_original, hmap_random_weights, hmap_random_target = pickle.load(f)\n",
    "                if attr_name in ['GuidedBP', 'Deconv']:\n",
    "                    postp = hmap_postprocess_wrapper('sum')\n",
    "                else:\n",
    "                    postp = hmap_postprocessing[attr_name]\n",
    "\n",
    "                for img_idx in selected_img_idxs[:1]:\n",
    "                    hmap_loaded.append((model_name, attr_name, 'image', \n",
    "                                        norm_image(val_images[0][0][0])))\n",
    "                    hmap_loaded.append((model_name, attr_name, 'original', \n",
    "                                        normalize_neg(postp(hmap_original[model_name, attr_name, img_idx]))))\n",
    "                    for layer_name in rnd_layers:\n",
    "                        layer_idx = get_layer_idx_full(model_name, nice_layer_names, layer_name)\n",
    "                        hmap_loaded.append((model_name, attr_name, layer_name, \n",
    "                                            normalize_neg(postp(hmap_random_weights[model_name, attr_name, img_idx, layer_idx]))))\n",
    "            except KeyError as e:\n",
    "                print(e)\n",
    "                pass\n",
    "    return hmap_loaded\n",
    "\n",
    "hmap_examplary = load_examplary_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outpath = hmap_output_dir + '/heatmap_{}_{}.pickle'.format('resnet50', \n",
    "                                                           'LRP-$\\\\alpha=1, \\\\beta=0$' )\n",
    "print(outpath)\n",
    "with open(outpath, 'rb') as f:\n",
    "    hmap_original, hmap_random_weights, hmap_random_target = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (_, _, img_idx, layer_idx), hmap in hmap_random_weights.items():\n",
    "    print(img_idx, (hmap==0).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n for (n, _, _, _, _) in analysers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('figures/sanity_checks', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 1\n",
    "selected_analysers = ['GuidedBP',\n",
    " 'Deconv',\n",
    " 'DTD',\n",
    " 'LRP-$\\\\alpha=1, \\\\beta=0$',\n",
    " 'LRP-$\\\\alpha=2, \\\\beta=1$',\n",
    " 'PatternAttr.',\n",
    " 'Gradient'\n",
    "]\n",
    "selected_layers = [\n",
    "    \"image\",\n",
    "    \"original\",\n",
    "    \"fc3\",\n",
    "    \"conv5_3\",\n",
    "    \"conv4_1\",\n",
    "    \"conv2_1\",\n",
    "    \"conv1_1\",\n",
    "]\n",
    "\n",
    "selected_layers\n",
    "selected_hmaps = []\n",
    "\n",
    "for (model_name, attr_name, layer_name, hmap) in hmap_examplary:\n",
    "    if model_name != 'vgg16':\n",
    "        continue\n",
    "    if attr_name not in selected_analysers:\n",
    "        continue\n",
    "    if layer_name not in selected_layers:\n",
    "        continue\n",
    "       \n",
    "    selected_hmaps.append(hmap)\n",
    "    \n",
    "plot_heatmap_grid(\n",
    "    selected_hmaps, len(selected_layers), row_labels=selected_analysers, \n",
    "    column_labels=selected_layers,\n",
    "    figsize=(3.9, 0.55*len(selected_analysers) + 0.1),\n",
    "    fig_path='figures/sanity_checks/heatmap_grid_figure1.pdf'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(IFrame('figures/sanity_checks/heatmap_grid_figure1.pdf', width=1000, height=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_analysers = [\n",
    " 'LRP-cmp-$\\\\alpha=1$',\n",
    " 'LRP-cmp-$\\\\alpha=2$',\n",
    "]\n",
    "\n",
    "\n",
    "for selected_model_name in model_names:\n",
    "    \n",
    "    selected_hmaps = []\n",
    "    selected_layers = {\n",
    "        'vgg16': [\n",
    "            \"image\",\n",
    "            \"original\",\n",
    "            \"fc3\",\n",
    "            \"conv5_3\",\n",
    "            \"conv4_1\",\n",
    "            \"conv2_1\",\n",
    "            \"conv1_1\",\n",
    "        ],\n",
    "        'resnet50': [\n",
    "            \"image\",\n",
    "            \"original\",\n",
    "            \"dense\",\n",
    "            \"block5_2\",\n",
    "            \"block3_3\",\n",
    "            \"block2_2\",\n",
    "            \"conv1\",\n",
    "        ]}[selected_model_name]\n",
    "    \n",
    "    for (model_name, attr_name, layer_name, hmap) in hmap_examplary:\n",
    "        if model_name != selected_model_name:\n",
    "            continue\n",
    "        if attr_name not in selected_analysers:\n",
    "            continue\n",
    "        if layer_name not in selected_layers:\n",
    "            print(layer_name)\n",
    "            continue\n",
    "\n",
    "        selected_hmaps.append(hmap)\n",
    "\n",
    "    outname = 'figures/sanity_checks/heatmap_grid_{}_lrp_cmp.pdf'.format(selected_model_name)\n",
    "    plot_heatmap_grid(\n",
    "        selected_hmaps, len(selected_layers), row_labels=selected_analysers, \n",
    "        column_labels=selected_layers,\n",
    "        figsize=(3.99, 1.1),\n",
    "        fig_path=outname\n",
    "    )\n",
    "    display(IFrame(outname, width=1000, height=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for selected_model_name in model_names:\n",
    "    print(model_name)\n",
    "    attr_for_model = OrderedDict()\n",
    "    layer_names = OrderedDict()\n",
    "    hmap_plot = []\n",
    "    for (model_name, attr_name, layer_name, hmap) in hmap_examplary:\n",
    "        if model_name != selected_model_name:\n",
    "            continue\n",
    "        attr_for_model[attr_name] = attr_name\n",
    "        layer_names[layer_name] = layer_name\n",
    "        hmap_plot.append(hmap)\n",
    "        \n",
    "    plot_heatmap_grid(\n",
    "        hmap_plot, len(layer_names), \n",
    "        row_labels=attr_for_model.keys(), \n",
    "        column_labels=layer_names.keys(),\n",
    "        figsize=(0.6*len(layer_names), 0.6*len(attr_for_model)),\n",
    "        fig_path='figures/sanity_checks/heatmap_grid_{}.pdf'.format(selected_model_name)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(IFrame('figures/sanity_checks/heatmap_grid_vgg16.pdf', width=1000, height=600))\n",
    "display(IFrame('figures/sanity_checks/heatmap_grid_resnet50.pdf', width=1000, height=600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls 'figures/sanity_checks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_name = 'LRP-$\\\\alpha=5, \\\\beta=4$'\n",
    "attr_name = 'PatternAttr.'\n",
    "hmap = hmap_random_weights['vgg16', attr_name, 673, 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
