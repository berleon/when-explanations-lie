{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When Explanations Lie: Why Many Modified BP Attributions fails\n",
    "\n",
    "\n",
    "## Two classes: Dog and cat saliency map for figure 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select gpu\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "import innvestigate\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import PIL \n",
    "import copy\n",
    "import contextlib\n",
    "\n",
    "import imp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from skimage.measure import compare_ssim \n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "from IPython.display import IFrame, display\n",
    "\n",
    "import keras\n",
    "import keras.backend\n",
    "import keras.models\n",
    "\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.applications.imagenet\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils as iutils\n",
    "import innvestigate.utils.visualizations as ivis\n",
    "from innvestigate.analyzer.relevance_based.relevance_analyzer import LRP\n",
    "from innvestigate.analyzer.base import AnalyzerNetworkBase, ReverseAnalyzerBase\n",
    "from innvestigate.analyzer.deeptaylor import DeepTaylor\n",
    "\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "from scipy.special import softmax\n",
    "\n",
    "import sys\n",
    "\n",
    "from when_explanations_lie import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "keras.backend.set_session(sess)\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to imagenet in `imagenet_dir.json`\n",
    "host, = ! hostname\n",
    "\n",
    "with open('imagenet_dir.json') as f:\n",
    "    imagenet_dir = json.load(f)[host]\n",
    "    \n",
    "print(\"using imagenet at: \", imagenet_dir)\n",
    "\n",
    "# path to examplary image\n",
    "ex_image_path = \"n01534433/ILSVRC2012_val_00015410.JPEG\"\n",
    "# number of images to run the evaluation\n",
    "n_selected_imgs = 200\n",
    "\n",
    "model_names = ['resnet50', 'vgg16']\n",
    "\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "# https://pixabay.com/photos/cat-kitten-dog-puppy-pet-2603395/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_meta(model_name, load_weights=True, clear_session=True):\n",
    "    if clear_session:\n",
    "        keras.backend.clear_session()\n",
    "    if model_name in ['vgg16', 'resnet50']:\n",
    "        model, innv_net, color_conversion = load_model(model_name, load_weights) \n",
    "        meta = ImageNetMeta(model, model_name, innv_net, n_selected_imgs, \n",
    "                            imagenet_dir, ex_image_path)\n",
    "    elif model_name == 'cifar10':\n",
    "        model, _, _ = load_model('cifar10', load_weights)\n",
    "        meta = CIFAR10Meta(model, n_selected_imgs)\n",
    "    else:\n",
    "        raise ValueError()\n",
    "    return model, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, meta = load_model_and_meta('vgg16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "for img, target in tqdm.tqdm_notebook(meta.images):\n",
    "    logits = model.predict(img)\n",
    "    top1 = logits.argmax()\n",
    "    correct.append(top1 == target)\n",
    "    \n",
    "print(\"Top-1 accuracy: \", np.mean(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imagenet_labels.json', 'r') as f:\n",
    "    idx_to_label =  json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! cp -r ~/images ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dog = PIL.Image.open('images/cat_dog_224.jpg')\n",
    "cat  = PIL.Image.open('images/cat_224.jpg')\n",
    "dog  = PIL.Image.open('images/dog_224.jpg')\n",
    "\n",
    "zebra_elephant = PIL.Image.open('images/zebra_elephant_224.jpg')\n",
    "zebra  = PIL.Image.open('images/zebra_224.jpg')\n",
    "elephant  = PIL.Image.open('images/elephant_224.jpg')\n",
    "\n",
    "two_class_pil_imgs = [\n",
    "    # Persian cat, King Charles Spaniel \n",
    "    ('cat_dog', cat_dog, cat, dog, 283, 156),  \n",
    "    # Zebra, African bush elephant\n",
    "    ('zebra_elephant', zebra_elephant, zebra, elephant, 340, 386)\n",
    "]\n",
    "two_class_imgs = [(\n",
    "    name,\n",
    "    preprocess_input(np.array(a_and_b).astype(np.float))[None], \n",
    "    preprocess_input(np.array(a).astype(np.float))[None], \n",
    "    preprocess_input(np.array(b, ).astype(np.float))[None], \n",
    "    a_cls,\n",
    "    b_cls\n",
    ") for name, a_and_b, a, b, a_cls, b_cls in two_class_pil_imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_name, ab, a, b, a_cls, b_cls in two_class_imgs:\n",
    "    logit_ab = model.predict(ab)[0]\n",
    "    logit_a = model.predict(a)[0]\n",
    "    logit_b = model.predict(b)[0]\n",
    "    \n",
    "    idx_ab = np.argsort(logit_ab)[::-1]\n",
    "    idx_a = np.argsort(logit_a)[::-1]\n",
    "    idx_b = np.argsort(logit_b)[::-1]\n",
    "    \n",
    "    \n",
    "    prob_a = softmax(logit_a, -1)\n",
    "    prob_b = softmax(logit_b, -1)\n",
    "    \n",
    "    for top_class in idx_a[:5]:\n",
    "        print(prob_a[top_class], top_class, idx_to_label[int(top_class)])\n",
    "        #print()\n",
    "        \n",
    "    print()\n",
    "        \n",
    "    for top_class in idx_b[:5]:\n",
    "        print(prob_b[top_class], top_class, idx_to_label[int(top_class)])\n",
    "        \n",
    "    print()\n",
    "    print(\"-\" * 60)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_neg(x):\n",
    "    vmax = np.percentile(x, 99)\n",
    "    vmin = np.percentile(x, 1)\n",
    "    x_pos = x * (x > 0)\n",
    "    x_neg = x * (x < 0)\n",
    "    x_pos = x_pos / vmax\n",
    "    x_neg = - x_neg / vmin\n",
    "    return np.abs(np.clip(x_pos + x_neg, -1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "innvestigate.analyzer.analyzers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monkey_patch_lrp_resnet import custom_add_bn_rule, get_custom_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmaps = OrderedDict()\n",
    "for model_name in ['vgg16']:\n",
    "    print(model_name)\n",
    "    #keras.backend.clear_session()\n",
    "    #model, meta = load_model_and_meta(model_name)\n",
    "    \n",
    "    with custom_add_bn_rule(get_custom_rule('lrp.alpha_1_beta_0', {})):\n",
    "        analyser = innvestigate.create_analyzer('lrp.alpha_1_beta_0', model, neuron_selection_mode=\"index\")\n",
    "        analyser.create_analyzer_model()\n",
    "    \n",
    "        for (img_name, ab, a, b, a_cls, b_cls) in two_class_imgs:\n",
    "            ab_explain_a = analyser.analyze(ab, a_cls)\n",
    "            ab_explain_b = analyser.analyze(ab, b_cls)\n",
    "\n",
    "            a_explain_a = analyser.analyze(a, a_cls)\n",
    "            b_explain_b = analyser.analyze(b, b_cls)\n",
    "\n",
    "            random_logit = np.random.choice([i for i in range(1000) if i not in [a_cls, b_cls]])\n",
    "            ab_explain_random = analyser.analyze(ab, random_logit)\n",
    "\n",
    "            hmaps[model_name, img_name, 'ab_explain_a'] = ab_explain_a\n",
    "            hmaps[model_name, img_name, 'ab_explain_b'] = ab_explain_b\n",
    "            hmaps[model_name, img_name, 'ab_explain_random'] = ab_explain_random\n",
    "            hmaps[model_name, img_name, 'a_explain_a'] = a_explain_a\n",
    "            hmaps[model_name, img_name, 'b_explain_b'] = b_explain_b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_abs(x, percentile=99.5):\n",
    "    return np.abs(normalize_visual(x, percentile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figdir = 'figures/two_class/'\n",
    "! rm {figdir}/*\n",
    "! mkdir -p {figdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hmap(hmap, save_path):\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(normalize_abs(hmap[0].sum(-1), 99.5), \n",
    "               vmin=-1, vmax=1, cmap='seismic') \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if save_path is not None:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, bbox_inches='tight', pad_inches=0.0)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def plot_hmap_diff(hmap, save_path):\n",
    "    plt.figure(figsize=(3, 2))\n",
    "    hmap = hmap[0].sum(-1) \n",
    "    hmap = np.clip(hmap, np.percentile(hmap, 1.0), np.percentile(hmap, 99.0))\n",
    "    abs_max = max(np.abs(hmap.min()), np.abs(hmap.max()))\n",
    "    vmin = - abs_max\n",
    "    vmax = abs_max\n",
    "    \n",
    "    plt.imshow(hmap, vmin=vmin, vmax=vmax, cmap='seismic') \n",
    "    cbar = plt.colorbar()\n",
    "    cbar.ax.tick_params(labelsize=14)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if save_path is not None:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, bbox_inches='tight', pad_inches=0.0)\n",
    "    plt.show()\n",
    "\n",
    "def plot_image(img, save_path=None):\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(image(img[0])[:, :, [2,1,0]])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if save_path is not None:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, bbox_inches='tight', pad_inches=0.0)\n",
    "    plt.show()\n",
    "\n",
    "def get_img_path(img_name, class_name):\n",
    "    return os.path.join(figdir, \"image_{}_{}.pdf\".format(img_name, class_name))\n",
    "\n",
    "def get_hmap_path(img_name, img_cls, explained_cls):\n",
    "    return os.path.join(figdir, \"hmap_{}_{}_{}.pdf\".format(img_name, img_cls, explained_cls))\n",
    "\n",
    "def get_l1_dist_path(img_name):\n",
    "    return os.path.join(figdir, \"l1_dist_{}.txt\".format(img_name))\n",
    "\n",
    "with sns.axes_style('white', {'font.family': 'serif'}):\n",
    "    for model_name in ['vgg16']:\n",
    "        for (img_name, ab, a, b, a_cls, b_cls) in two_class_imgs:\n",
    "            cls_a = idx_to_label[a_cls].replace(' ', '_')\n",
    "            cls_b = idx_to_label[b_cls].replace(' ', '_')\n",
    "\n",
    "            print(cls_a, a_cls, cls_b, b_cls)\n",
    "            plot_image(ab, get_img_path(img_name, 'both'))\n",
    "            plot_image(a, get_img_path(img_name, cls_a))\n",
    "            plot_image(b, get_img_path(img_name, cls_b))\n",
    "\n",
    "            hmap  = hmaps[model_name, img_name, 'a_explain_a']\n",
    "            plot_hmap(hmap, get_hmap_path(img_name, cls_a, cls_a))\n",
    "\n",
    "            hmap  = hmaps[model_name, img_name, 'b_explain_b']\n",
    "            plot_hmap(hmap, get_hmap_path(img_name, cls_b, cls_b))\n",
    "\n",
    "            hmap  = hmaps[model_name, img_name, 'ab_explain_a']\n",
    "            plot_hmap(hmap, get_hmap_path(img_name, 'both', cls_a))\n",
    "\n",
    "\n",
    "            hmap  = hmaps[model_name, img_name, 'ab_explain_b']\n",
    "            plot_hmap(hmap, get_hmap_path(img_name, 'both', cls_b))\n",
    "\n",
    "            hmap  = hmaps[model_name, img_name, 'ab_explain_random']\n",
    "            plot_hmap(hmap, get_hmap_path(img_name, 'both', 'random'))\n",
    "\n",
    "            hmap_a  = hmaps[model_name, img_name, 'ab_explain_a']\n",
    "            hmap_b  = hmaps[model_name, img_name, 'ab_explain_b']\n",
    "            hmap_a = normalize_abs(hmap_a)\n",
    "            hmap_b = normalize_abs(hmap_b)\n",
    "            plot_hmap_diff(hmap_a - hmap_b, get_hmap_path(img_name, 'both', 'diff'))\n",
    "\n",
    "            l1_distance = np.abs(normalize_abs(hmaps[model_name, img_name, 'ab_explain_a']) -  \n",
    "                                 normalize_abs(hmaps[model_name, img_name, 'ab_explain_b'])).mean()\n",
    "            with open(get_l1_dist_path(img_name), 'w') as f:\n",
    "                f.write(\"{:.6f}\".format(l1_distance))\n",
    "\n",
    "            print(\"L1 distance: {:.6f}\".format(l1_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(IFrame(figdir + '/hmap_cat_dog_both_King_Charles_Spaniel.pdf', 800, 600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {figdir}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
